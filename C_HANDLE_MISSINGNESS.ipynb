{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cf06c8",
   "metadata": {},
   "source": [
    "# Load Packages and Merged Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "795bca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "\n",
    "merged = pd.read_parquet(Path(\"PROCESSED/DATA/merged.parquet\")) # From previous step (B_MERGE_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c630f",
   "metadata": {},
   "source": [
    "### Step 1: Transforming Numerical Missing to True Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98883a8b",
   "metadata": {},
   "source": [
    "Getting all associated numerical codes associated with missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2232ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "INVALID_PATTERN = re.compile(\n",
    "    r\"(?:refused|don['']?t\\s*know|missing|blank but applicable|\"\n",
    "    r\"(?:can|could)\\s*not\\s*assess|unknown|not\\s*ascertained)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def get_invalid_codes(codebook):\n",
    "    result = {}\n",
    "    codebook_df = pd.read_csv(codebook)\n",
    "    if 'variable_name' not in codebook_df.columns:\n",
    "        return\n",
    "    for var_name in codebook_df['variable_name']:\n",
    "        table = codebook_df[codebook_df['variable_name'] == var_name]['table'].item()\n",
    "        if type(table) is float:\n",
    "            continue\n",
    "\n",
    "        df = pd.read_html(StringIO(table))[0]\n",
    "        \n",
    "\n",
    "        if \"Code or Value\" in df.columns and \"Value Description\" in df.columns:\n",
    "            # rows with invalid desc\n",
    "            # regex warning handled by using non-capturing groups above\n",
    "            invalid = df[\"Value Description\"].astype(str).str.contains(INVALID_PATTERN, na=False)\n",
    "            if invalid.any():\n",
    "                codes = df.loc[invalid, \"Code or Value\"].astype(str).str.strip().tolist()\n",
    "                result[var_name] = codes\n",
    "    return result\n",
    "\n",
    "# Populate \"invalid_map\" (variable name to invalid codes) for questionnaire_data\n",
    "questionnaire_codebooks_path = Path(\"RAW/CODEBOOKS/questionnaire_data\")\n",
    "codebook_files = list(questionnaire_codebooks_path.rglob(\"*.csv\"))\n",
    "\n",
    "invalid_map = {}\n",
    "for codebook_file in codebook_files:\n",
    "    invalid_codes = get_invalid_codes(codebook_file)\n",
    "    if invalid_codes:\n",
    "        invalid_map.update(invalid_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a948ff5",
   "metadata": {},
   "source": [
    "Saving the mapper to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d28cefcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved invalid_map_questionnaire_2017_2020.csv to ./PROCESSED/DATA/invalid_map_questionnaire_2017_2020.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the invalid map to a CSV file\n",
    "df_invalid_map = pd.DataFrame([\n",
    "    {'variable': var, 'invalid_code': code}\n",
    "    for var, codes in invalid_map.items()\n",
    "    for code in codes\n",
    "])\n",
    "\n",
    "directory = \"./PROCESSED/DATA\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "save_path = directory + \"/invalid_map_questionnaire_2017_2020.csv\"\n",
    "df_invalid_map.to_csv(save_path, index = False)\n",
    "print(f\"Saved invalid_map_questionnaire_2017_2020.csv to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d5c797",
   "metadata": {},
   "source": [
    "Apply transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b014ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table to set 7,77,9,99 etc to NaN\n",
    "# invalid_map = pd.read_csv(\"./PROCESSED/DATA/invalid_map_questionnaire_2017_2020.csv\")\n",
    "invalid_map = pd.read_csv(\"./PROCESSED/DATA/invalid_map_questionnaire_2017_2020.csv\", dtype=str)\n",
    "invalid_dict = invalid_map.groupby(\"variable\")[\"invalid_code\"].apply(list).to_dict()\n",
    " \n",
    "# loop and replace invalid (don't know, refused, etc.) with NaN\n",
    "# for var, codes in invalid_dict.items():\n",
    "#     match = [c for c in df.columns if c.startswith(var)]\n",
    "#     if not match: continue\n",
    "#     col = match[0]\n",
    "#     df[col] = df[col].replace(codes, pd.NA)\n",
    " \n",
    "for var, codes in invalid_dict.items():\n",
    "    cols = [c for c in merged.columns if c == var or c.endswith(var)]\n",
    "    # print(cols)\n",
    "    if not cols: \n",
    "        continue\n",
    "    # match \"7\"/\"77\"/\".\" and also 7/77 (numbers)\n",
    "    codes_mixed = set(codes) | {int(c) for c in codes if c.isdigit()}\n",
    "    merged[cols] = merged[cols].mask(merged[cols].isin(codes_mixed), pd.NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e195fe3",
   "metadata": {},
   "source": [
    "### Step 2: Selective Categorical Encoding and Dropping\n",
    "\n",
    "Manual screening was done for more granular dropping and encoding measures\n",
    "- `SHEETS/dict_data_type.xlsx`\n",
    "- `TABLES/init_selection_tab.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "72a2e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_selection_tab = pd.read_excel('SHEETS/dict_data_type.xlsx', sheet_name='init_selection')\n",
    "init_selection_tab.to_csv('TABLES/init_selection_tab.csv', index=False)\n",
    "drop_vars = init_selection_tab.loc[init_selection_tab[\"IS_KEEP\"] == False, \"variable_name\"]\n",
    "cat_vars = init_selection_tab.loc[init_selection_tab[\"IS_CATEGORICAL\"] == True, \"variable_name\"]\n",
    "\n",
    "drop_vars = drop_vars.str.split('_').str[0] # Extract variable label\n",
    "cat_vars = cat_vars.str.split('_').str[0] # Extract variable labelcat_vars\n",
    "merged_base_names = merged.columns.to_series().str.split('__').str[-1] # Extract variable label\n",
    "\n",
    "# Perform special selected drop\n",
    "drop_vars_mask = merged_base_names.isin(drop_vars)\n",
    "merged_dropped = merged.drop(\n",
    "    columns = merged.columns[drop_vars_mask]\n",
    ")\n",
    "\n",
    "# Perform special categorical encoding\n",
    "merged_base_names = merged_dropped.columns.to_series().str.split('__').str[-1]\n",
    "merged_base_names = merged_base_names.reset_index(drop = True)\n",
    "for var in cat_vars:\n",
    "    if var in merged_base_names.values:\n",
    "        idx = merged_base_names.index[merged_base_names.values == var]\n",
    "        column_name = merged_dropped.columns[idx]\n",
    "        merged_dropped[column_name] = merged_dropped[column_name].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8992b3",
   "metadata": {},
   "source": [
    "### Step 3: Remove the columns with more than 30% missingness  \n",
    "\n",
    "This is a rudamentary drop. Our intention is to make a more granular pass later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f6194eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1107 columns with >30% missingness.\n",
      "Dropped 672 rows with missing target variable (P_GHB__LBXGH).\n",
      "Cleaning log saved to C:\\HW\\LIFEBOAT\\POOL\\CSE881\\BLEED_FROM_THE_THROAT\\CSE881_PROJ\\LOG\\log_cleaning.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 2a - Remove columns with more than 30% missingness\n",
    "num_rows = merged.shape[0]\n",
    "threshold = 0.3 * num_rows\n",
    "\n",
    "cols_to_drop = merged.columns[merged.isnull().sum() > threshold]\n",
    "merged_dropped = merged.drop(columns=cols_to_drop)\n",
    "\n",
    "# Step 2b - Remove rows with no target variable\n",
    "target_col = 'P_GHB__LBXGH'\n",
    "before_rows = merged_dropped.shape[0]\n",
    "merged_dropped = merged_dropped.dropna(subset=[target_col])\n",
    "after_rows = merged_dropped.shape[0]\n",
    "rows_dropped = before_rows - after_rows\n",
    "\n",
    "# Logging the cleaning steps\n",
    "log_path = Path(\"LOG/log_cleaning.txt\")\n",
    "with open(log_path, \"w\") as log:\n",
    "    log.write(\"==== Data Cleaning Log ====\\n\\n\")\n",
    "\n",
    "    # Log columns dropped\n",
    "    log.write(f\"Columns dropped (>30% missingness): {len(cols_to_drop)}\\n\")\n",
    "    if len(cols_to_drop) > 0:\n",
    "        log.write(\"\\n\".join(cols_to_drop))\n",
    "        log.write(\"\\n\\n\")\n",
    "    else:\n",
    "        log.write(\"None\\n\\n\")\n",
    "\n",
    "    # Log rows dropped\n",
    "    log.write(f\"Rows dropped with missing target variable ({target_col}): {rows_dropped}\\n\")\n",
    "\n",
    "print(f\"Dropped {len(cols_to_drop)} columns with >30% missingness.\")\n",
    "print(f\"Dropped {rows_dropped} rows with missing target variable ({target_col}).\")\n",
    "print(f\"Cleaning log saved to {log_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de9f15",
   "metadata": {},
   "source": [
    "### Save to .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "907288a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged_and_dropped.parquet to ./PROCESSED/DATA/merged_and_dropped.parquet\n"
     ]
    }
   ],
   "source": [
    "directory = \"./PROCESSED/DATA\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "save_path = directory + \"/merged_and_dropped.parquet\"\n",
    "\n",
    "merged.to_parquet(save_path, index = False)\n",
    "print(f\"Saved merged_and_dropped.parquet to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brigand",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
