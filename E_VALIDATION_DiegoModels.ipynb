{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae294d",
   "metadata": {},
   "source": [
    "# Collinearity and Leakage Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98e8ff",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "__Collinearity (Moved to later part)__  \n",
    "step 2 - Run the VIF -> drop the highest -> Repeat (Threshold VIF < 5)  \n",
    "Note:\n",
    "* unlike p-value which the choice of drop is arbitrary, VIF check against the remaining variables which give clear values\n",
    "* modern ML can handle multicollinearity but GLM struggle  \n",
    "* the VIF will be run after variable selection only for GLM, but not for trees\n",
    "\n",
    "__Leakage Test__  \n",
    "step 3 - Check p-value against the predictor for regression data. Check if p-value is suspiciously high.  \n",
    "step 4 - Run random forest against the data (can use default param). Check top 10 feature importance and check manually for a potential leakage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78fdce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# stats\n",
    "from scipy.stats import ks_2samp, chi2_contingency, pearsonr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99acfa5",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "> KS test: 2 variables (1.60%) have p < 0.05\n",
    "> Chi-square test: 4 variables (3.05%) have p < 0.05\n",
    ">\n",
    "> Conclusion: The train-test split preserved the distribution well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4127549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PROCESSED/DATA/merged_and_dropped.cat_cols.json\") as f:\n",
    "    cat_cols = json.load(f)\n",
    "\n",
    "X_train = pd.read_parquet(\"INPUTS/TRAIN/X_train.parquet\")\n",
    "X_test = pd.read_parquet(\"INPUTS/TEST/X_test.parquet\")\n",
    "y_train = pd.read_parquet(\"INPUTS/TRAIN/y_train.parquet\")\n",
    "y_test = pd.read_parquet(\"INPUTS/TEST/y_test.parquet\")\n",
    "\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n",
    "\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f657a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                  0.107458\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m           0.055981\n",
      "P_ALB_CR__URDACT_Albumin_creatinine_ratio_mg_g              0.049917\n",
      "P_MCQ__MCQ366D                                              0.021577\n",
      "P_MCQ__MCQ300C                                              0.019748\n",
      "P_TCHOL__LBDTCSI_Total_Cholesterol_mmol_L                   0.019056\n",
      "P_ALB_CR__URXUMS_Albumin_urine_mg_L                         0.017563\n",
      "P_BPQ__BPQ020_Ever_told_you_had_high_blood_pressure_2.0     0.017517\n",
      "P_BIOPRO__LBDSCHSI_Cholesterol_refrigerated_serum_mmol_L    0.016390\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                       0.015303\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf.fit(X_encoded, y_train.iloc[:, 0])\n",
    "importances = pd.Series(rf.feature_importances_, index=X_encoded.columns)\n",
    "top10 = importances.sort_values(ascending=False).head(10)\n",
    "print(top10)\n",
    "# top10.to_csv(\"LOG/rf_leakage_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5759f",
   "metadata": {},
   "source": [
    "#### Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0d2cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best CV score: 0.6015451407695722\n",
      "CV AUC at best-AUC params: 0.8752691103239566\n",
      "CV F1 at best-AUC params: 0.6015451407695722\n",
      "CV Accuracy at best-AUC params: 0.8501732669693746\n",
      "Train accuracy: 0.934,  F1: 0.862, AUC: 0.993\n",
      "Test  accuracy: 0.870,  F1: 0.643, AUC: 0.898\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      1642\n",
      "         1.0       0.79      0.23      0.36       306\n",
      "\n",
      "    accuracy                           0.87      1948\n",
      "   macro avg       0.83      0.61      0.64      1948\n",
      "weighted avg       0.86      0.87      0.84      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, make_scorer, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# ensure target is categorical\n",
    "y_train_cat = y_train.iloc[:, 0].astype(\"category\")\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(\"category\")\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# model\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc_ovr',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_encoded, y_train_cat)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "# evaluate on train/test\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_rf.predict(X_encoded)\n",
    "y_pred_test  = best_rf.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_cat, best_rf.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_cat, best_rf.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c41d420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.857,  F1: 0.688\n",
      "Test  accuracy: 0.867,  F1: 0.693\n",
      "Train AUC: 0.866\n",
      "Test  AUC: 0.881\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92      1642\n",
      "         1.0       0.63      0.36      0.46       306\n",
      "\n",
      "    accuracy                           0.87      1948\n",
      "   macro avg       0.76      0.66      0.69      1948\n",
      "weighted avg       0.85      0.87      0.85      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# target as categorical\n",
    "y_train_cat = y_train.iloc[:, 0].astype(\"category\")\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(\"category\")\n",
    "\n",
    "# unregularized logistic regression (GLM)\n",
    "model = LogisticRegression(\n",
    "    penalty=None,        # FIX: unregularized\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=500,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "model.fit(X_encoded, y_train_cat)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = model.predict(X_encoded)\n",
    "y_pred_test  = model.predict(X_test_encoded)\n",
    "\n",
    "# metrics\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average=\"macro\")\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average=\"macro\")\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}\")\n",
    "print(f\"Train AUC: {roc_auc_score(y_train_cat, model.predict_proba(X_encoded)[:, 1]):.3f}\")\n",
    "print(f\"Test  AUC: {roc_auc_score(y_test_cat, model.predict_proba(X_test_encoded)[:, 1]):.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e85bfb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best CV score: 0.7787033779911746\n",
      "CV AUC at best-AUC params: 0.9155415564742245\n",
      "CV F1 at best-AUC params: 0.7787033779911746\n",
      "CV Accuracy at best-AUC params: 0.8885601773924675\n",
      "Train accuracy: 0.942,  F1: 0.888, AUC: 0.981\n",
      "Test  accuracy: 0.914,  F1: 0.817, AUC: 0.938\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.81      0.59      0.68       306\n",
      "\n",
      "    accuracy                           0.91      1948\n",
      "   macro avg       0.87      0.78      0.82      1948\n",
      "weighted avg       0.91      0.91      0.91      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, make_scorer\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# target\n",
    "y_train_cat = y_train.iloc[:, 0].astype(int)\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(int)\n",
    "\n",
    "# parameter grid (XGB version)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# model\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# scorers\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_encoded, y_train_cat)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "# evaluate\n",
    "best_xgb = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_xgb.predict(X_encoded)\n",
    "y_pred_test  = best_xgb.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_cat, best_xgb.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_cat, best_xgb.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9382ac5c-9a7b-4db1-8c70-c7eae91a2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best CV score: 0.5067559409414645\n",
      "CV AUC at best-AUC params: 0.8535214610423522\n",
      "CV F1 at best-AUC params: 0.5067559409414645\n",
      "CV Accuracy at best-AUC params: 0.8348953268547586\n",
      "Train accuracy: 0.898,  F1: 0.760, AUC: 0.983\n",
      "Test  accuracy: 0.849,  F1: 0.508, AUC: 0.860\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92      1642\n",
      "           1       0.80      0.05      0.10       306\n",
      "\n",
      "    accuracy                           0.85      1948\n",
      "   macro avg       0.82      0.52      0.51      1948\n",
      "weighted avg       0.84      0.85      0.79      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# --- ExtraTreesClassifier ---\n",
    "\n",
    "# binary/int version of the target (0/1)\n",
    "y_train_bin = y_train.iloc[:, 0].astype(int)\n",
    "y_test_bin  = y_test.iloc[:, 0].astype(int)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "et = ExtraTreesClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=et,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train_bin)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "best_et = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_et.predict(X_encoded)\n",
    "y_pred_test  = best_et.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_bin, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_bin, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_bin, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_bin, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_bin, best_et.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_bin, best_et.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_bin, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eaedcf0-c0d3-49f6-a681-9a263cd9275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl.metadata (1.4 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl (27.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: graphviz, lightgbm, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21 lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c88509-ec44-4313-8544-51b9c6ca423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "Best parameters: {'depth': 4, 'learning_rate': 0.1, 'n_estimators': 400}\n",
      "Best CV score: 0.7742526759671201\n",
      "CV AUC at best-AUC params: 0.9144010650081252\n",
      "CV F1 at best-AUC params: 0.7742526759671201\n",
      "CV Accuracy at best-AUC params: 0.8867629355431448\n",
      "Train accuracy: 0.965,  F1: 0.934, AUC: 0.991\n",
      "Test  accuracy: 0.912,  F1: 0.816, AUC: 0.936\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.78      0.60      0.68       306\n",
      "\n",
      "    accuracy                           0.91      1948\n",
      "   macro avg       0.86      0.79      0.82      1948\n",
      "weighted avg       0.91      0.91      0.91      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# --- CatBoost ---\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 400],\n",
    "    'depth': [4, 6, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "}\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    random_state=42,\n",
    "    thread_count=-1,\n",
    "    verbose=0  # silence per-iteration output\n",
    ")\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=cat,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train_bin)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "best_cat = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_cat.predict(X_encoded)\n",
    "y_pred_test  = best_cat.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_bin, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_bin, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_bin, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_bin, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_bin, best_cat.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_bin, best_cat.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_bin, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f2ff61e-68df-45e7-8372-8b1e7878d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 200, 'min_samples_leaf': 50}\n",
      "Best CV score: 0.7722170427499749\n",
      "CV AUC at best-AUC params: 0.915831299609526\n",
      "CV F1 at best-AUC params: 0.7722170427499749\n",
      "CV Accuracy at best-AUC params: 0.8859933106015614\n",
      "Train accuracy: 0.942,  F1: 0.888, AUC: 0.980\n",
      "Test  accuracy: 0.911,  F1: 0.813, AUC: 0.933\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.79      0.59      0.68       306\n",
      "\n",
      "    accuracy                           0.91      1948\n",
      "   macro avg       0.86      0.78      0.81      1948\n",
      "weighted avg       0.91      0.91      0.91      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# --- HistGradientBoostingClassifier ---\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_iter': [100, 200],\n",
    "    'min_samples_leaf': [20, 50],\n",
    "}\n",
    "\n",
    "hgb = HistGradientBoostingClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train_bin)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "best_hgb = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_hgb.predict(X_encoded)\n",
    "y_pred_test  = best_hgb.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_bin, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_bin, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_bin, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_bin, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_bin, best_hgb.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_bin, best_hgb.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_bin, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9687afd0-8388-4c87-b571-facd17482baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 200, 'num_leaves': 31}\n",
      "Best CV score: 0.7704216027713929\n",
      "CV AUC at best-AUC params: 0.9157653959098013\n",
      "CV F1 at best-AUC params: 0.7704216027713929\n",
      "CV Accuracy at best-AUC params: 0.887918460694741\n",
      "Train accuracy: 1.000,  F1: 1.000, AUC: 1.000\n",
      "Test  accuracy: 0.911,  F1: 0.811, AUC: 0.937\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.79      0.59      0.67       306\n",
      "\n",
      "    accuracy                           0.91      1948\n",
      "   macro avg       0.86      0.78      0.81      1948\n",
      "weighted avg       0.91      0.91      0.91      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightgbm\")\n",
    "\n",
    "# --- LightGBM ---\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [-1, 5, 10],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 63],\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1      # <- this suppresses the info messages\n",
    "    # verbosity=-1  # (alternative name in some versions)\n",
    ")\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train_bin)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "best_lgbm = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_lgbm.predict(X_encoded)\n",
    "y_pred_test  = best_lgbm.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_bin, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_bin, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_bin, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_bin, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_bin, best_lgbm.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_bin, best_lgbm.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_bin, y_pred_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
