{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a0c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tabnanny import verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./PROCESSED/DATA\"\n",
    "file_name = \"merged_and_dropped.parquet\"\n",
    "path = f\"{directory}/{file_name}\"\n",
    "\n",
    "df = pd.read_parquet(path)\n",
    "\n",
    "with open(\"./PROCESSED/DATA/merged_and_dropped.cat_cols.json\") as f:\n",
    "    cat_cols = json.load(f)\n",
    "\n",
    "df[cat_cols] = df[cat_cols].astype(\"category\")\n",
    "\n",
    "# lookup for new target variable (CLASSIFICATION)\n",
    "target = pd.read_excel(\"./SHEETS/merged_data_analysis.xlsx\", sheet_name=\"target\")\n",
    "df = df.merge(target[['SEQN', 'IS_DIABETES']], on='SEQN', how='left')\n",
    "\n",
    "# drop SEQN\n",
    "df = df.drop(columns=['SEQN'])\n",
    "\n",
    "dtypes = df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train-test\n",
    "# DIRECT LEAKAGE COLUMNS TO DROP\n",
    "drop_cols = ['Alpha-glucosidase inhibitor', 'Biguanide', 'DPP-4 inhibitor', 'GLP-1 receptor agonist',\n",
    "             'Insulin', 'Meglitinide', 'SGLT2 inhibitor', 'Sulfonylurea', 'Thiazolidinedione (TZD)']\n",
    "\n",
    "X = df.drop(columns=['LBXGH', 'IS_DIABETES'] + drop_cols)\n",
    "y = df[['IS_DIABETES']]\n",
    "X_train_pre_cleaned, X_test_pre_cleaned, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d3759",
   "metadata": {},
   "source": [
    "# Imputation\n",
    "Random Forest imputation using sklearn iterativeimputer. MissForest doesn't allow to re-use the model to impute the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ebac7",
   "metadata": {},
   "source": [
    "step 1 - encode both train/test   \n",
    "step 2 - fit iterativeimputer random forest on train set only  \n",
    "step 3 - use trained imputation model on both train and test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02370dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is encoded to ordinal encoder since iterative imputer only accepts numerical values\n",
    "# Trees can handle ordinal encoded categorical variables without issue\n",
    "# Using one-hot encoding would increase the number of features too much\n",
    "# However, linear models would require one-hot encoding to avoid implying ordinality\n",
    "# And also for distribution tests later, we need to decode back to original categories\n",
    "\n",
    "# named cat_cols instead of cat_vars to avoid confusion\n",
    "cat_cols = X_train_pre_cleaned.select_dtypes(include=['category']).columns.tolist()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X_train_ordinal = X_train_pre_cleaned.copy()\n",
    "X_test_ordinal = X_test_pre_cleaned.copy()\n",
    "X_train_ordinal[cat_cols] = ordinal_encoder.fit_transform(X_train_ordinal[cat_cols])\n",
    "X_test_ordinal[cat_cols] = ordinal_encoder.transform(X_test_ordinal[cat_cols])\n",
    "\n",
    "# transform \"unknown\" into NaN so the imputer imputes them\n",
    "for c in cat_cols:\n",
    "    X_train_ordinal[c] = X_train_ordinal[c].replace(-1, np.nan)\n",
    "    X_test_ordinal[c] = X_test_ordinal[c].replace(-1, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7da6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7789, 247)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 50.40\n",
      "[IterativeImputer] Change: 9925.064719938873, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 73.77\n",
      "[IterativeImputer] Change: 2660.558527318766, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 97.81\n",
      "[IterativeImputer] Change: 3853.4003927231565, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 122.07\n",
      "[IterativeImputer] Change: 2050.436734990701, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 146.31\n",
      "[IterativeImputer] Change: 2541.5002748319635, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 170.53\n",
      "[IterativeImputer] Change: 2863.3418966109434, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 194.77\n",
      "[IterativeImputer] Change: 2117.582944695898, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 218.95\n",
      "[IterativeImputer] Change: 3654.4051234856283, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 243.27\n",
      "[IterativeImputer] Change: 3022.6561127030645, scaled tolerance: 68.0 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 267.61\n",
      "[IterativeImputer] Change: 2108.42879339525, scaled tolerance: 68.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# For a random forest imputer, we don't really need a huge number of trees\n",
    "# Imputation is about generating stable estimates, not prediction accuracy\n",
    "# So we can limit the number of trees to speed up computation\n",
    "# Usually n=10-50 is sufficient, but we can go a bit higher if it's unstable\n",
    "\n",
    "def extra_trees_imputer():\n",
    "    et_imputer = IterativeImputer(\n",
    "        estimator=ExtraTreesRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=10,\n",
    "            min_samples_leaf=40,\n",
    "            min_samples_split=60,\n",
    "            max_features='sqrt',\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        n_nearest_features=40,\n",
    "        max_iter=10,\n",
    "        initial_strategy='median',\n",
    "        random_state=42,\n",
    "        imputation_order='ascending',\n",
    "        verbose=2\n",
    "    )\n",
    "    return et_imputer\n",
    "\n",
    "imputer = extra_trees_imputer()\n",
    "\n",
    "X_train = imputer.fit_transform(X_train_ordinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd1616",
   "metadata": {},
   "source": [
    "> The iterative imputer did not reach the convergence tolerance. However, the change is stabilized and non-divergent after first few iterations, which suffice for practical purpose. The imputation was terminated after 10 rounds as further iteration unlikely will produce any meaningful improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c038853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (1948, 247)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 3.59\n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 7.18\n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 10.87\n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 14.75\n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 18.41\n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 22.04\n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 25.64\n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 29.22\n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 32.79\n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 36.59\n"
     ]
    }
   ],
   "source": [
    "X_test = imputer.transform(X_test_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7521b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to DataFrames\n",
    "X_train_imputed = pd.DataFrame(X_train, columns=X_train_ordinal.columns, index=X_train_ordinal.index)\n",
    "X_test_imputed  = pd.DataFrame(X_test, columns=X_test_ordinal.columns,  index=X_test_ordinal.index)\n",
    "\n",
    "# rounding categorical codes to valid range before inverse_transform\n",
    "for i, c in enumerate(cat_cols):\n",
    "    n = len(ordinal_encoder.categories_[i])\n",
    "    X_train_imputed[c] = np.clip(np.rint(X_train_imputed[c]).astype(int), 0, n-1)\n",
    "    X_test_imputed[c] = np.clip(np.rint(X_test_imputed[c]).astype(int),  0, n-1)\n",
    "\n",
    "# restore categorical dtype\n",
    "X_train_imputed[cat_cols] = ordinal_encoder.inverse_transform(X_train_imputed[cat_cols])\n",
    "X_test_imputed[cat_cols] = ordinal_encoder.inverse_transform(X_test_imputed[cat_cols])\n",
    "for col in cat_cols:\n",
    "    X_train_imputed[col] = X_train_imputed[col].astype('category')\n",
    "    X_test_imputed[col] = X_test_imputed[col].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c98ec6",
   "metadata": {},
   "source": [
    "#### Binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d76cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning\n",
    "# SLQ300_Usual_sleep_time_on_weekdays_or_workdays\n",
    "# SLQ320_Usual_sleep_time_on_weekends\n",
    "# 1_very_early: 19-20\n",
    "# 2_early: 21-22\n",
    "# 3_normal: 23-00\n",
    "# 4_late: 01-02\n",
    "# 5_extreme: else\n",
    "\n",
    "\n",
    "cols = [\"P_SLQ__SLQ320_Usual_sleep_time_on_weekends\", \"P_SLQ__SLQ300_Usual_sleep_time_on_weekdays_or_workdays\"]\n",
    "\n",
    "for df in (X_train_imputed, X_test_imputed):\n",
    "    for col in cols:\n",
    "        # convert \"HH:MM\" to rounded hour 0–23\n",
    "        df[col] = pd.to_datetime(df[col], format=\"%H:%M\", errors=\"coerce\").dt.round(\"h\").dt.hour\n",
    "\n",
    "        # binning according to plan above\n",
    "        df[col] = np.select(\n",
    "            [\n",
    "                # use isin instead of between since we already round it anyway and to handle the midnight\n",
    "                df[col].isin([19, 20]),       # 1 very early: 19–20\n",
    "                df[col].isin([21, 22]),       # 2 early: 21–22\n",
    "                df[col].isin([23, 0]),         # 3 normal: 23–00\n",
    "                df[col].isin([1, 2]),          # 4 late: 01–02\n",
    "            ],\n",
    "            [1, 2, 3, 4],\n",
    "            default=5                         # 5 extreme: everything else / NaN\n",
    "        ).astype(\"int64\")   # convert to clear integer, but later it will be preserved as category dtype by json files\n",
    "\n",
    "\n",
    "# Taken out, but kept here for reference\n",
    "# SLQ310_Usual_wake_time_on_weekdays_or_workdays\n",
    "# SLQ330_Usual_wake_time_on_weekends\n",
    "# 1_very_early: 3-4\n",
    "# 2_early: 5-6\n",
    "# 3_normal: 7-8\n",
    "# 4_late: 9-10\n",
    "# 5_extreme: else\n",
    "\n",
    "# SLD012_Sleep_hours_weekdays_or_workdays\n",
    "# SLD013_Sleep_hours_weekends\n",
    "# ≤5 hours -> Very short\n",
    "# >5-<7 hours -> Short\n",
    "# 7-<9 hours -> Normal\n",
    "# ≥9 hours -> Long\n",
    "cols = [\"P_SLQ__SLD012_Sleep_hours_weekdays_or_workdays\", \"P_SLQ__SLD013_Sleep_hours_weekends\"]\n",
    "\n",
    "for df in (X_train_imputed, X_test_imputed):\n",
    "    for col in cols:\n",
    "        # convert to numeric\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "        # binning according to plan above\n",
    "        df[col] = np.select(\n",
    "            [\n",
    "                df[col] <= 5,                   # 1: very short\n",
    "                (df[col] > 5) & (df[col] < 7),  # 2: short\n",
    "                (df[col] >= 7) & (df[col] < 9), # 3: normal\n",
    "                df[col] >= 9                  # 4: long\n",
    "            ],\n",
    "            [1, 2, 3, 4],\n",
    "            default=4                         # 5 extreme: everything else / NaN\n",
    "        ).astype(\"int64\")   # convert to clear integer, but later it will be preserved as category dtype by json files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57191e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"INPUTS/TRAIN\", exist_ok=True)\n",
    "os.makedirs(\"INPUTS/TEST\", exist_ok=True)\n",
    "os.makedirs(\"RESULTS\", exist_ok=True)\n",
    "\n",
    "X_train_imputed.to_parquet(\"INPUTS/TRAIN/X_train.parquet\", index=False)\n",
    "X_test_imputed.to_parquet(\"INPUTS/TEST/X_test.parquet\", index=False)\n",
    "y_train.to_parquet(\"INPUTS/TRAIN/y_train.parquet\", index=False)\n",
    "y_test.to_parquet(\"INPUTS/TEST/y_test.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
