{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83cb20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6788882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://wwwn.cdc.gov/Nchs/Data/Nhanes/Public/2017/DataFiles/P_DEMO.htm\"\n",
    "# soup = BeautifulSoup(requests.get(url).text, \"html.parser\")\n",
    "\n",
    "# records = []\n",
    "# for h3 in soup.find_all(\"h3\"):\n",
    "#     var_name = h3.get_text(strip=True).replace(\"Variable:\", \"\").strip()\n",
    "#     bold = h3.find_next(\"b\", string=\"English Text:\")\n",
    "#     desc = bold.next_sibling.strip() if bold and bold.next_sibling else \"\"\n",
    "#     if var_name:\n",
    "#         records.append((var_name, desc))\n",
    "\n",
    "# df = pd.DataFrame(records, columns=[\"Variable\", \"Description\"])\n",
    "# df = df[df[\"Variable\"].str.contains(\" - \", na=False)]\n",
    "# df[[\"Code\", \"Variable_Description\"]] = df[\"Variable\"].str.split(\" - \", n=1, expand=True)\n",
    "# df = df[[\"Code\", \"Variable_Description\", \"Description\"]].reset_index(drop=True)\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "805ade42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Dietary&Cycle=2017-2020'\n",
    "# soup = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "\n",
    "# data = []\n",
    "# for table in soup.find_all('table'):\n",
    "#     for row in table.find_all('tr')[1:]:  # Skip header\n",
    "#         cols = row.find_all('td')\n",
    "#         if len(cols) >= 3:\n",
    "#             def extract_link(cell):\n",
    "#                 tag = cell.find('a')\n",
    "#                 text = tag.get_text(strip=True) if tag else cell.get_text(strip=True)\n",
    "#                 url = tag.get('href', '') if tag else ''\n",
    "#                 url = 'https://wwwn.cdc.gov' + url if url and not url.startswith('http') else url\n",
    "#                 return text, url\n",
    "            \n",
    "#             doc_text, doc_url = extract_link(cols[2])\n",
    "#             data_file, data_url = extract_link(cols[3]) if len(cols) >= 4 else ('', '')\n",
    "            \n",
    "#             data.append({\n",
    "#                 'Years': cols[0].get_text(strip=True),\n",
    "#                 'Data File Name': cols[1].get_text(strip=True),\n",
    "#                 'Doc File': doc_text,\n",
    "#                 'Doc URL': doc_url,\n",
    "#                 'Data File': data_file,\n",
    "#                 'Data URL': data_url,\n",
    "#                 'Date Published': cols[4].get_text(strip=True) if len(cols) >= 5 else ''\n",
    "#             })\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# print(f\"Total rows: {len(df)}\\n\\n{df.to_string()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f62a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 data files\n",
      "\n",
      "Processing: Dietary Interview - Individual Foods, First Day...\n",
      "Processing: Dietary Interview - Individual Foods, Second Day...\n",
      "Processing: Dietary Interview - Total Nutrient Intakes, First Day...\n",
      "Processing: Dietary Interview - Total Nutrient Intakes, Second Day...\n",
      "Processing: Dietary Interview Technical Support File - Food Codes...\n",
      "Processing: Dietary Supplement Database - Blend Information...\n",
      "Processing: Dietary Supplement Database - Ingredient Information...\n",
      "Processing: Dietary Supplement Database - Product Information...\n",
      "Processing: Dietary Supplement Use 24-Hour - Individual Dietary Supplements, First Day...\n",
      "Processing: Dietary Supplement Use 24-Hour - Individual Dietary Supplements, Second Day...\n",
      "Processing: Dietary Supplement Use 24-Hour - Total Dietary Supplements, First Day...\n",
      "Processing: Dietary Supplement Use 24-Hour - Total Dietary Supplements, Second Day...\n",
      "Processing: Dietary Supplement Use 30-Day - Individual Dietary Supplements...\n",
      "Processing: Dietary Supplement Use 30-Day - Total Dietary Supplements...\n",
      "\n",
      "Total variables extracted: 768\n",
      "        Code                   Variable_Description  \\\n",
      "0       SEQN             Respondent sequence number   \n",
      "1   WTDRD1PP          Dietary day one sample weight   \n",
      "2   WTDR2DPP          Dietary two-day sample weight   \n",
      "3   DR1ILINE       Food/Individual component number   \n",
      "4   DR1DRSTZ                  Dietary recall status   \n",
      "5   DR1EXMER                    Interviewer ID code   \n",
      "6      DRABF         Breast-fed infant (either day)   \n",
      "7     DRDINT               Number of days of intake   \n",
      "8    DR1DBIH  # of days b/w intake and HH interview   \n",
      "9     DR1DAY                 Intake day of the week   \n",
      "10   DR1LANG        Language respondent used mostly   \n",
      "11  DR1CCMNM                Combination food number   \n",
      "12  DR1CCMTX                  Combination food type   \n",
      "13     DR1FS                         Source of food   \n",
      "14  DR1IFDCD                         USDA food code   \n",
      "15  DR1IGRMS                                  Grams   \n",
      "16  DR1IKCAL                          Energy (kcal)   \n",
      "17  DR1IPROT                           Protein (gm)   \n",
      "18  DR1ICARB                      Carbohydrate (gm)   \n",
      "19  DR1ISUGR                      Total sugars (gm)   \n",
      "\n",
      "                                          Data_File  \n",
      "0   Dietary Interview - Individual Foods, First Day  \n",
      "1   Dietary Interview - Individual Foods, First Day  \n",
      "2   Dietary Interview - Individual Foods, First Day  \n",
      "3   Dietary Interview - Individual Foods, First Day  \n",
      "4   Dietary Interview - Individual Foods, First Day  \n",
      "5   Dietary Interview - Individual Foods, First Day  \n",
      "6   Dietary Interview - Individual Foods, First Day  \n",
      "7   Dietary Interview - Individual Foods, First Day  \n",
      "8   Dietary Interview - Individual Foods, First Day  \n",
      "9   Dietary Interview - Individual Foods, First Day  \n",
      "10  Dietary Interview - Individual Foods, First Day  \n",
      "11  Dietary Interview - Individual Foods, First Day  \n",
      "12  Dietary Interview - Individual Foods, First Day  \n",
      "13  Dietary Interview - Individual Foods, First Day  \n",
      "14  Dietary Interview - Individual Foods, First Day  \n",
      "15  Dietary Interview - Individual Foods, First Day  \n",
      "16  Dietary Interview - Individual Foods, First Day  \n",
      "17  Dietary Interview - Individual Foods, First Day  \n",
      "18  Dietary Interview - Individual Foods, First Day  \n",
      "19  Dietary Interview - Individual Foods, First Day  \n"
     ]
    }
   ],
   "source": [
    "def extract_link(cell):\n",
    "    tag = cell.find('a')\n",
    "    text = tag.get_text(strip=True) if tag else cell.get_text(strip=True)\n",
    "    url = tag.get('href', '') if tag else ''\n",
    "    return text, ('https://wwwn.cdc.gov' + url if url and not url.startswith('http') else url)\n",
    "\n",
    "# Get data files\n",
    "soup = BeautifulSoup(requests.get('https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Dietary&Cycle=2017-2020').content, 'html.parser')\n",
    "data = []\n",
    "for row in [r for t in soup.find_all('table') for r in t.find_all('tr')[1:]]:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) >= 3:\n",
    "        doc_text, doc_url = extract_link(cols[2])\n",
    "        data_file, data_url = extract_link(cols[3]) if len(cols) >= 4 else ('', '')\n",
    "        data.append({'Years': cols[0].get_text(strip=True), 'Data File Name': cols[1].get_text(strip=True),\n",
    "                     'Doc File': doc_text, 'Doc URL': doc_url, 'Data File': data_file, 'Data URL': data_url,\n",
    "                     'Date Published': cols[4].get_text(strip=True) if len(cols) >= 5 else ''})\n",
    "\n",
    "df_files = pd.DataFrame(data)\n",
    "print(f\"Found {len(df_files)} data files\\n\")\n",
    "\n",
    "# Extract variables from each doc\n",
    "all_variables = []\n",
    "for idx, row in df_files.iterrows():\n",
    "    if not row['Doc URL']:\n",
    "        continue\n",
    "    print(f\"Processing: {row['Data File Name']}...\")\n",
    "    soup = BeautifulSoup(requests.get(row['Doc URL']).text, \"html.parser\")\n",
    "    \n",
    "    records = [(h3.get_text(strip=True).replace(\"Variable:\", \"\").strip(),\n",
    "                h3.find_next(\"b\", string=\"English Text:\").next_sibling.strip() if (bold := h3.find_next(\"b\", string=\"English Text:\")) and bold.next_sibling else \"\")\n",
    "               for h3 in soup.find_all(\"h3\")\n",
    "               if (var := h3.get_text(strip=True).replace(\"Variable:\", \"\").strip()) and \" - \" in var and re.match(r'^[A-Z0-9]+$', var.split(\" - \")[0].strip())]\n",
    "    \n",
    "    if records:\n",
    "        df_vars = pd.DataFrame(records, columns=[\"Variable\", \"Description\"])\n",
    "        df_vars[[\"Code\", \"Variable_Description\"]] = df_vars[\"Variable\"].str.split(\" - \", n=1, expand=True)\n",
    "        df_vars['Data_File'] = row['Data File Name']\n",
    "        all_variables.append(df_vars[[\"Code\", \"Variable_Description\", \"Description\", \"Data_File\"]])\n",
    "\n",
    "df_all = pd.concat(all_variables, ignore_index=True) if all_variables else pd.DataFrame()\n",
    "\n",
    "# drop column description from df_all\n",
    "df_all = df_all.drop(columns=['Description'])\n",
    "\n",
    "print(f\"\\nTotal variables extracted: {len(df_all)}\\n{df_all.head(20)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "131dd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to csv\n",
    "df_all.to_csv('TABLES/data_dict_dietary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
