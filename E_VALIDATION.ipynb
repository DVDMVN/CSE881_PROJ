{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae294d",
   "metadata": {},
   "source": [
    "# Collinearity and Leakage Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98e8ff",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "__Collinearity (Moved to later part)__  \n",
    "step 2 - Run the VIF -> drop the highest -> Repeat (Threshold VIF < 5)  \n",
    "Note:\n",
    "* unlike p-value which the choice of drop is arbitrary, VIF check against the remaining variables which give clear values\n",
    "* modern ML can handle multicollinearity but GLM struggle  \n",
    "* the VIF will be run after variable selection only for GLM, but not for trees\n",
    "\n",
    "__Leakage Test__  \n",
    "step 3 - Check p-value against the predictor for regression data. Check if p-value is suspiciously high.  \n",
    "step 4 - Run random forest against the data (can use default param). Check top 10 feature importance and check manually for a potential leakage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fdce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# stats\n",
    "from scipy.stats import ks_2samp, chi2_contingency, pearsonr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99acfa5",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "> KS test: 2 variables (1.60%) have p < 0.05\n",
    "> Chi-square test: 4 variables (3.05%) have p < 0.05\n",
    ">\n",
    "> Conclusion: The train-test split preserved the distribution well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4127549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PROCESSED/DATA/merged_and_dropped.cat_cols.json\") as f:\n",
    "    cat_cols = json.load(f)\n",
    "\n",
    "X_train = pd.read_parquet(\"INPUTS/TRAIN/X_train.parquet\")\n",
    "X_test = pd.read_parquet(\"INPUTS/TEST/X_test.parquet\")\n",
    "y_train = pd.read_parquet(\"INPUTS/TRAIN/y_train.parquet\")\n",
    "y_test = pd.read_parquet(\"INPUTS/TEST/y_test.parquet\")\n",
    "\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n",
    "\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f07838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test: 2 variables (1.55%) have p < 0.05\n",
      "Chi-square test: 3 variables (2.40%) have p < 0.05\n"
     ]
    }
   ],
   "source": [
    "ks_results = []\n",
    "chi2_results = []\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if col == \"LBXGH\":\n",
    "        continue\n",
    "\n",
    "    # if str(X_train[col].dtype) == \"category\":\n",
    "    #     # Chi-square test for categorical\n",
    "    #     contingency = pd.crosstab(X_train[col], X_test[col])\n",
    "\n",
    "    #     # skip if no valid data for chi-square\n",
    "    #     if contingency.size == 0 or contingency.shape[0] < 2 or contingency.shape[1] < 2: continue\n",
    "\n",
    "    #     chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "    #     chi2_results.append({\"variable\": col, \"Chi2_stat\": chi2, \"p_value\": p})\n",
    "\n",
    "    if str(X_train[col].dtype) == \"category\":\n",
    "        train_counts = X_train[col].value_counts(dropna=False)\n",
    "        test_counts = X_test[col].value_counts(dropna=False)\n",
    "        # cats = sorted(set(train_counts.index) | set(test_counts.index))\n",
    "        cats = list(set(train_counts.index) | set(test_counts.index))\n",
    "        contingency = pd.DataFrame({\n",
    "            \"train\": train_counts.reindex(cats, fill_value=0),\n",
    "            \"test\": test_counts.reindex(cats, fill_value=0)\n",
    "        }).T\n",
    "\n",
    "        if contingency.shape[1] >= 2:  # need at least two categories\n",
    "            chi2, p, dof, expected = chi2_contingency(contingency)\n",
    "            chi2_results.append({\"variable\": col, \"Chi2_stat\": chi2, \"p_value\": p})\n",
    "\n",
    "\n",
    "    else:\n",
    "        # KS test for continuous\n",
    "        ks_stat, ks_p = ks_2samp(X_train[col].dropna(), X_test[col].dropna())\n",
    "        ks_results.append({\"variable\": col, \"KS_stat\": ks_stat, \"p_value\": ks_p})\n",
    "\n",
    "\n",
    "ks_results_df = pd.DataFrame(ks_results)\n",
    "chi2_results_df = pd.DataFrame(chi2_results)\n",
    "\n",
    "# KS summary\n",
    "total_ks = len(ks_results_df)\n",
    "n_sig_ks = (ks_results_df[\"p_value\"] < 0.05).sum()\n",
    "pct_sig_ks = n_sig_ks / total_ks * 100\n",
    "print(f\"KS test: {n_sig_ks} variables ({pct_sig_ks:.2f}%) have p < 0.05\")\n",
    "\n",
    "# Chi-square summary\n",
    "total_chi2 = len(chi2_results_df)\n",
    "n_sig_chi2 = (chi2_results_df[\"p_value\"] < 0.05).sum()\n",
    "pct_sig_chi2 = n_sig_chi2 / total_chi2 * 100\n",
    "print(f\"Chi-square test: {n_sig_chi2} variables ({pct_sig_chi2:.2f}%) have p < 0.05\")\n",
    "\n",
    "\n",
    "# Save results for audit purposes\n",
    "pd.DataFrame(ks_results).to_csv(\"LOG/log_KS.csv\", index=False)\n",
    "pd.DataFrame(chi2_results).to_csv(\"LOG/log_Chi2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949caa25",
   "metadata": {},
   "source": [
    "__Collinearity (Moved to later part)__  \n",
    "step 2 - Run the VIF -> drop the highest -> Repeat (Threshold VIF < 5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc651641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "# X_vif = X_train[numeric_cols].copy()\n",
    "# vif = pd.DataFrame({\n",
    "#         'feature': X_vif.columns,\n",
    "#         'VIF': [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b241aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Drop P_BIOPRO__LBDSTPSI_Total_Protein_g_L (VIF=434311.7)\n",
      "Iteration 2: Drop P_CBC__LBXMCVSI_Mean_cell_volume_fL (VIF=157805.5)\n",
      "Iteration 3: Drop P_CBC__LBXHCT_Hematocrit (VIF=60156.0)\n"
     ]
    }
   ],
   "source": [
    "# numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "# X_vif = X_train[numeric_cols].dropna()\n",
    "\n",
    "# # initialize\n",
    "# vif_summary = pd.DataFrame({'feature': X_vif.columns})\n",
    "\n",
    "# for iteration in range(1, 4):\n",
    "#     # calculate VIF\n",
    "#     vif_values = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "#     vif = pd.DataFrame({\n",
    "#         'feature': X_vif.columns,\n",
    "#         f'VIF_iter{iteration}': vif_values\n",
    "#     })\n",
    "    \n",
    "#     vif_summary = vif_summary.merge(vif, on='feature', how='left')\n",
    "\n",
    "#     # find max VIF then drop\n",
    "#     max_idx = vif_values.index(max(vif_values))\n",
    "#     drop_col = X_vif.columns[max_idx]\n",
    "#     max_vif = vif_values[max_idx]\n",
    "    \n",
    "#     print(f\"Iteration {iteration}: Drop {drop_col} (VIF={max_vif:.1f})\")\n",
    "#     X_vif = X_vif.drop(columns=drop_col)\n",
    "    \n",
    "# vif_summary.to_csv(\"RESULTS/VIF_log.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38710a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Drop P_BIOPRO__LBDSTPSI_Total_Protein_g_L: VIF=434311.7\n",
      "[2] Drop P_CBC__LBXMCVSI_Mean_cell_volume_fL: VIF=157805.5\n",
      "[3] Drop P_CBC__LBXHCT_Hematocrit: VIF=60156.0\n",
      "[4] Drop P_FETIB__LBDTIBSI_Tot_Iron_Binding_Capacity_TIBC_umol_L: VIF=38903.5\n",
      "[5] Drop P_BIOPRO__LBXSNASI_Sodium_mmol_L: VIF=37253.5\n",
      "[6] Drop P_CBC__LBXWBCSI_White_blood_cell_count_1000_cells_uL: VIF=15441.5\n",
      "[7] Drop P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg: VIF=7896.9\n",
      "[8] Drop P_CBC__LBXMCHSI_Mean_cell_hemoglobin_pg: VIF=7475.7\n",
      "[9] Drop P_BMX__BMXHT_Standing_Height_cm: VIF=7077.2\n",
      "[10] Drop P_CBC__LBXNEPCT_Segmented_neutrophils_percent: VIF=3510.4\n",
      "[11] Drop P_CBC__LBXMC_Mean_Cell_Hgb_Conc_g_dL: VIF=2056.2\n",
      "[12] Drop P_BIOPRO__LBDSCHSI_Cholesterol_refrigerated_serum_mmol_L: VIF=1706.8\n",
      "[13] Drop P_WHQ__WHD010_Current_self_reported_height_inches: VIF=1688.8\n",
      "[14] Drop P_BIOPRO__LBDSCASI_Total_Calcium_mmol_L: VIF=962.8\n",
      "[15] Drop P_BIOPRO__LBXSCLSI_Chloride_mmol_L: VIF=883.2\n",
      "[16] Drop P_FETIB__LBDIRNSI_Iron_frozen_Serum_umol_L: VIF=741.6\n",
      "[17] Drop P_BPXO__BPXOSY2_Systolic_2nd_oscillometric_reading: VIF=678.8\n",
      "[18] Drop P_BPXO__BPXOPLS2_Pulse_2nd_oscillometric_reading: VIF=649.0\n",
      "[19] Drop P_BMX__BMXARML_Upper_Arm_Length_cm: VIF=554.6\n",
      "[20] Drop P_BMX__BMXHIP_Hip_Circumference_cm: VIF=517.6\n",
      "[21] Drop P_BMX__BMXWT_Weight_kg: VIF=515.3\n",
      "[22] Drop P_BPXO__BPXOSY3_Systolic_3rd_oscillometric_reading: VIF=439.7\n",
      "[23] Drop P_BPXO__BPXODI2_Diastolic_2nd_oscillometric_reading: VIF=418.5\n",
      "[24] Drop P_BPXO__BPXOPLS3_Pulse_3rd_oscillometric_reading: VIF=401.1\n",
      "[25] Drop P_CBC__LBXHGB_Hemoglobin_g_dL: VIF=337.8\n",
      "[26] Drop P_BMX__BMXWAIST_Waist_Circumference_cm: VIF=310.6\n",
      "[27] Drop P_BPXO__BPXODI1_Diastolic_1st_oscillometric_reading: VIF=309.8\n",
      "[28] Drop P_BMX__BMXARMC_Arm_Circumference_cm: VIF=262.4\n",
      "[29] Drop P_PBCD__LBDTHGSI_Blood_mercury_total_nmol_L: VIF=250.8\n",
      "[30] Drop P_WHQ__WHD020_Current_self_reported_weight_pounds: VIF=236.2\n",
      "[31] Drop P_BIOPRO__LBXSAL_Albumin_refrigerated_serum_g_dL: VIF=223.2\n",
      "[32] Drop P_BMX__BMXLEG_Upper_Leg_Length_cm: VIF=198.6\n",
      "[33] Drop P_CBC__LBXRDW_Red_cell_distribution_width: VIF=150.6\n",
      "[34] Drop P_CBC__LBXRBCSI_Red_blood_cell_count_million_cells_uL: VIF=133.2\n",
      "[35] Drop P_FETIB__LBDPCT_Transferrin_Saturation: VIF=129.1\n",
      "[36] Drop P_WHQ__WHD140_Self_reported_greatest_weight_pounds: VIF=119.4\n",
      "[37] Drop P_BIOPRO__LBXSC3SI_Bicarbonate_mmol_L: VIF=114.8\n",
      "[38] Drop P_BPXO__BPXOSY1_Systolic_1st_oscillometric_reading: VIF=104.3\n",
      "[39] Drop P_CBC__LBXMPSI_Mean_platelet_volume_fL: VIF=99.5\n",
      "[40] Drop P_CBC__LBXMOPCT_Monocyte_percent: VIF=80.5\n",
      "[41] Drop P_WHQ__WHD050_Self_reported_weight_1_yr_ago_pounds: VIF=74.9\n",
      "[42] Drop P_BIOPRO__LBDSGBSI_Globulin_g_L: VIF=64.3\n",
      "[43] Drop P_BPXO__BPXODI3_Diastolic_3rd_oscillometric_reading: VIF=54.2\n",
      "[44] Drop P_PBCD__LBDBSESI_Blood_selenium_umol_L: VIF=52.3\n",
      "[45] Drop P_BIOPRO__LBDSPHSI_Phosphorus_mmol_L: VIF=52.2\n",
      "[46] Drop P_BPXO__BPXOPLS1_Pulse_1st_oscillometric_reading: VIF=47.2\n",
      "[47] Drop P_BMX__BMXBMI_Body_Mass_Index_kg_m_2: VIF=42.2\n",
      "[48] Drop P_MCQ__MCQ160E: VIF=39.6\n",
      "[49] Drop P_MCQ__MCQ160L: VIF=35.3\n",
      "[50] Drop P_MCQ__MCQ160F: VIF=33.5\n",
      "[51] Drop P_FETIB__LBDUIBSI_UIBC_Serum_umol_L: VIF=32.6\n",
      "[52] Drop P_TCHOL__LBDTCSI_Total_Cholesterol_mmol_L: VIF=31.3\n",
      "[53] Drop P_MCQ__MCQ160B: VIF=30.6\n",
      "[54] Drop P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m: VIF=29.6\n",
      "[55] Drop P_BIOPRO__LBXSLDSI_Lactate_Dehydrogenase_LDH_IU_L: VIF=29.5\n",
      "[56] Drop P_MCQ__MCQ160P: VIF=27.7\n",
      "[57] Drop P_MCQ__MCQ366A: VIF=26.0\n",
      "[58] Drop P_MCQ__MCQ160C: VIF=25.9\n",
      "[59] Drop P_CBC__LBDNENO_Segmented_neutrophils_num_1000_cell_uL: VIF=25.2\n",
      "[60] Drop P_WHQ__WHD120_Self_reported_weight_age_25_pounds: VIF=23.1\n",
      "[61] Drop P_MCQ__MCQ160M: VIF=22.2\n",
      "[62] Drop P_DEMO__RIDAGEYR_Age_in_years_at_screening: VIF=21.5\n",
      "[63] Drop P_MCQ__MCQ366C: VIF=20.4\n",
      "[64] Drop P_BIOPRO__LBDSUASI_Uric_acid_umol_L: VIF=19.9\n",
      "[65] Drop P_MCQ__MCQ160D: VIF=19.8\n",
      "[66] Drop P_HDL__LBDHDDSI_Direct_HDL_Cholesterol_mmol_L: VIF=18.8\n",
      "[67] Drop P_CBC__LBXEOPCT_Eosinophils_percent: VIF=18.0\n",
      "[68] Drop P_MCQ__MCQ366D: VIF=17.6\n",
      "[69] Drop P_CBC__LBXPLTSI_Platelet_count_1000_cells_uL: VIF=17.2\n",
      "[70] Drop P_IHGEM__LBDBGESI_Mercury_ethyl_nmol_L: VIF=16.7\n",
      "[71] Drop P_CBC__LBXLYPCT_Lymphocyte_percent: VIF=14.7\n",
      "[72] Drop P_DEMO__INDFMPIR_Ratio_of_family_income_to_poverty: VIF=14.4\n",
      "[73] Drop P_MCQ__MCQ371C: VIF=13.5\n",
      "[74] Drop P_MCQ__MCQ371A: VIF=12.2\n",
      "[75] Drop P_MCQ__MCQ366B: VIF=12.1\n",
      "[76] Drop P_BIOPRO__LBDSBUSI_Blood_Urea_Nitrogen_mmol_L: VIF=12.0\n",
      "[77] Drop P_CBC__LBDMONO_Monocyte_number_1000_cells_uL: VIF=11.7\n",
      "[78] Drop P_CBC__LBXBAPCT_Basophils_percent: VIF=10.5\n",
      "[79] Drop P_MCQ__MCQ160A: VIF=10.1\n",
      "[80] Drop P_WHQ__WHQ150_Age_when_heaviest_weight: VIF=9.7\n",
      "[81] Drop P_MCQ__MCQ371B: VIF=9.4\n",
      "[82] Drop P_TST__LBXLUH_Luteinizing_Hormone_mIU_mL: VIF=9.4\n",
      "[83] Drop P_BIOPRO__LBDSIRSI_Iron_refrigerated_serum_umol_L: VIF=8.6\n",
      "[84] Drop P_PBCD__LBDBMNSI_Blood_manganese_nmol_L: VIF=7.8\n",
      "[85] Drop P_MCQ__MCQ371D: VIF=7.3\n",
      "[86] Drop P_TST__LBDANDSI_Androstenedione_nmol_L: VIF=5.6\n",
      "[87] Drop P_MCQ__MCQ300A: VIF=5.3\n",
      "[88] Drop P_BIOPRO__LBDSCRSI_Creatinine_refrigerated_serum_umol_L: VIF=5.2\n",
      "VIF run finished with 43 features remaining\n"
     ]
    }
   ],
   "source": [
    "# numeric_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "# X_vif = X_train[numeric_cols].dropna()\n",
    "\n",
    "# # initialize\n",
    "# vif_summary = pd.DataFrame({'feature': X_vif.columns})\n",
    "\n",
    "# iteration = 0\n",
    "# while True:\n",
    "#     iteration += 1\n",
    "    \n",
    "#     # calculate VIF\n",
    "#     vif_values = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "#     max_vif = max(vif_values)\n",
    "    \n",
    "#     vif = pd.DataFrame({\n",
    "#         'feature': X_vif.columns,\n",
    "#         f'VIF_iter{iteration}': vif_values\n",
    "#     })\n",
    "    \n",
    "#     vif_summary = vif_summary.merge(vif, on='feature', how='left')\n",
    "    \n",
    "#     # break when all VIF < 5\n",
    "#     if max_vif < 5:\n",
    "#         break\n",
    "    \n",
    "#     # find max VIF then drop\n",
    "#     max_idx = vif_values.index(max_vif)\n",
    "#     drop_col = X_vif.columns[max_idx]\n",
    "    \n",
    "#     print(f\"[{iteration}] Drop {drop_col}: VIF={max_vif:.1f}\")\n",
    "#     X_vif = X_vif.drop(columns=drop_col)\n",
    "\n",
    "# vif_summary.to_csv(\"LOG/VIF_log.csv\", index=False)\n",
    "# print(f\"VIF run finished with {len(X_vif.columns)} features remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suspect list:\n",
      "Empty DataFrame\n",
      "Columns: [variable, correlation, p_value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# rows = []\n",
    "# for col in num_cols:\n",
    "#     x = X_train[col]\n",
    "#     r, p = pearsonr(x, y_train.iloc[:, 0]) # because (n,1) not (n,)\n",
    "#     rows.append((col, r, p))\n",
    "\n",
    "# df = pd.DataFrame(rows, columns=[\"variable\", \"correlation\", \"p_value\"])\n",
    "# df.to_csv(\"LOG/leakage_pvalue.csv\")\n",
    "\n",
    "# suspect = df[df[\"correlation\"].abs() > 0.6]\n",
    "# print(\"suspect list:\")\n",
    "# print(suspect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f657a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biguanide                                            0.177011\n",
      "Insulin                                              0.175790\n",
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening           0.048060\n",
      "Sulfonylurea                                         0.024929\n",
      "P_BIOPRO__LBXSAPSI_Alkaline_Phosphatase_ALP_IU_L     0.020622\n",
      "P_BIOPRO__LBXSCLSI_Chloride_mmol_L                   0.015296\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m    0.014529\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                0.013685\n",
      "P_TST__LBXSHBG_SHBG_nmol_L                           0.013501\n",
      "P_CBC__LBXRDW_Red_cell_distribution_width            0.012215\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # one-hot encode categorical variables\n",
    "# X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "# rf.fit(X_encoded, y_train.iloc[:, 0])\n",
    "# importances = pd.Series(rf.feature_importances_, index=X_encoded.columns)\n",
    "# top10 = importances.sort_values(ascending=False).head(10)\n",
    "# print(top10)\n",
    "# top10.to_csv(\"LOG/rf_leakage_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5759f",
   "metadata": {},
   "source": [
    "#### Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e418861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9edd4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best CV R²: 0.49567844507192954\n",
      "Train R²:  0.888,  RMSE: 0.349\n",
      "Test  R²:  0.539,  RMSE: 0.782\n"
     ]
    }
   ],
   "source": [
    "# parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV R²:\", grid.best_score_)\n",
    "\n",
    "# evaluate on test set\n",
    "best_rf = grid.best_estimator_\n",
    "y_pred_train = best_rf.predict(X_encoded)\n",
    "y_pred_test = best_rf.predict(X_test_encoded)\n",
    "\n",
    "r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "print(f\"Train R²:  {r2_train:.3f},  RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Test  R²:  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2215842",
   "metadata": {},
   "source": [
    "#### Test with no survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7917e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best params: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "CV best R²: 0.499\n",
      "Train R²:  0.898, RMSE: 0.333\n",
      "Test  R²:  0.542, RMSE: 0.779\n"
     ]
    }
   ],
   "source": [
    "prefixes = [\n",
    "    \"P_ALQ\",\n",
    "    \"P_AUQ\",\n",
    "    \"P_BPQ\",\n",
    "    \"P_CBQPFC\",\n",
    "    \"P_DBQ\",\n",
    "    \"P_DIQ\",\n",
    "    \"P_DPQ\",\n",
    "    \"P_FSQ\",\n",
    "    \"P_HEQ\",\n",
    "    \"P_HIQ\",\n",
    "    \"P_HSQ\",\n",
    "    \"P_HUQ\",\n",
    "    \"P_IMQ\",\n",
    "    \"P_INQ\",\n",
    "    \"P_KIQ_U\",\n",
    "    \"P_MCQ\",\n",
    "]\n",
    "\n",
    "cols_to_drop = [c for c in X_encoded.columns if any(c.startswith(p) for p in prefixes)]\n",
    "X_train_no_survey = X_encoded.drop(columns=cols_to_drop)\n",
    "X_test_no_survey = X_test_encoded.drop(columns=cols_to_drop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train_no_survey, y_train.iloc[:, 0])\n",
    "\n",
    "# Best model\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = best_rf.predict(X_train_no_survey)\n",
    "y_pred_test  = best_rf.predict(X_test_no_survey)\n",
    "\n",
    "# Metrics\n",
    "r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "r2_test  = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "rmse_test  = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "print(f\"CV best R²: {grid.best_score_:.3f}\")\n",
    "print(f\"Train R²:  {r2_train:.3f}, RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Test  R²:  {r2_test:.3f}, RMSE: {rmse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b8d349",
   "metadata": {},
   "source": [
    "#### Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b934ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "CV best R²: 0.45508896683667\n",
      "Train R²:  0.976, RMSE: 0.163\n",
      "Test  R²:  0.499,  RMSE: 0.815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "extra = ExtraTreesRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"CV best R²:\", grid.best_score_)\n",
    "\n",
    "# evaluate on test\n",
    "best_extra = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_extra.predict(X_encoded)\n",
    "y_pred_test  = best_extra.predict(X_test_encoded)\n",
    "\n",
    "r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "r2_test  = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "rmse_test  = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "print(f\"Train R²:  {r2_train:.3f}, RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Test  R²:  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94017bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters: {'max_depth': 6, 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "CV best R²: 0.42771870414529617\n",
      "Train R²:  0.551, RMSE: 0.699\n",
      "Test  R²:  0.440,  RMSE: 0.862\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [6],\n",
    "    'min_samples_split': [10],\n",
    "    'min_samples_leaf': [10],\n",
    "}\n",
    "\n",
    "extra = ExtraTreesRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=extra,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"CV best R²:\", grid.best_score_)\n",
    "\n",
    "# evaluate on test\n",
    "best_extra = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_extra.predict(X_encoded)\n",
    "y_pred_test  = best_extra.predict(X_test_encoded)\n",
    "\n",
    "r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "r2_test  = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "rmse_test  = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "print(f\"Train R²:  {r2_train:.3f}, RMSE: {rmse_train:.3f}\")\n",
    "print(f\"Test  R²:  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b338c91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Per-fold CV R²:\n",
      "  split0_test_score: 0.477\n",
      "  split1_test_score: 0.501\n",
      "  split2_test_score: 0.510\n",
      "Mean CV R²: 0.496\n",
      "Std CV R²:  0.014\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# cv = pd.DataFrame(grid.cv_results_)\n",
    "# best_row = cv.loc[cv['rank_test_score'].idxmin()]  # lowest rank = best\n",
    "\n",
    "# # grab all test scores from each CV split\n",
    "# fold_cols = [c for c in cv.columns if c.startswith('split') and c.endswith('test_score')]\n",
    "# best_folds = {col: best_row[col] for col in fold_cols}\n",
    "\n",
    "# print(\"Best parameters:\", best_row['params'])\n",
    "# print(\"Per-fold CV R²:\")\n",
    "# for k, v in best_folds.items():\n",
    "#     print(f\"  {k}: {v:.3f}\")\n",
    "\n",
    "# print(f\"Mean CV R²: {best_row['mean_test_score']:.3f}\")\n",
    "# print(f\"Std CV R²:  {best_row['std_test_score']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c83e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best parameters: {'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 5, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best CV R²: 0.38394621149835917\n",
      "Train R²:  0.649,  RMSE: 0.618\n",
      "Test  R²:  0.381,  RMSE: 0.906\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # encode\n",
    "# X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "# X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "# X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# # parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [200],          # stable averaging, not the lever here\n",
    "#     'max_depth': [5, 10, 15],        # cap depth\n",
    "#     'min_samples_split': [5, 10, 15],   # require more samples to split\n",
    "#     'min_samples_leaf': [5, 10, 15],  # bigger leaves = smoother fit\n",
    "#     'max_features': ['sqrt', 'log2'],  # limit features per split to add randomness\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# grid = GridSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# grid.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# print(\"Best CV R²:\", grid.best_score_)\n",
    "\n",
    "# # evaluate on test set\n",
    "# best_rf = grid.best_estimator_\n",
    "# y_pred_train = best_rf.predict(X_encoded)\n",
    "# y_pred_test = best_rf.predict(X_test_encoded)\n",
    "\n",
    "# r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "# r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "# rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "# print(f\"Train R²:  {r2_train:.3f},  RMSE: {rmse_train:.3f}\")\n",
    "# print(f\"Test  R²:  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7301b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best params (full features): {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV R² (full features): 0.508\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best params (top-200): {'max_depth': None, 'max_features': 0.3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best CV R² (top-200): 0.512\n",
      "Train R²:  0.895,  RMSE: 0.338\n",
      "Test  R²:  0.526,  RMSE: 0.793\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # encode\n",
    "# X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "# X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "# X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [200],\n",
    "#     'max_depth': [10, None],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'min_samples_leaf': [2, 5],\n",
    "#     'max_features': ['sqrt', 0.3]\n",
    "# }\n",
    "\n",
    "# # --- Part 2: Grid search on full features ---\n",
    "# rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# grid_full = GridSearchCV(\n",
    "#     estimator=rf,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# grid_full.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "# print(\"Best params (full features):\", grid_full.best_params_)\n",
    "# print(f\"Best CV R² (full features): {grid_full.best_score_:.3f}\")\n",
    "\n",
    "# # --- Part 3–4: Feature selection using the best model ---\n",
    "# best_rf_full = grid_full.best_estimator_\n",
    "# importances = pd.Series(best_rf_full.feature_importances_, index=X_encoded.columns)\n",
    "# top200 = importances.sort_values(ascending=False).head(200).index\n",
    "\n",
    "# X_train_sel = X_encoded[top200]\n",
    "# X_test_sel = X_test_encoded[top200]\n",
    "\n",
    "# # --- Part 5: Grid search again on top 200 features ---\n",
    "# rf_sel = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# grid_sel = GridSearchCV(\n",
    "#     estimator=rf_sel,\n",
    "#     param_grid=param_grid,\n",
    "#     cv=3,\n",
    "#     scoring='r2',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# grid_sel.fit(X_train_sel, y_train.iloc[:, 0])\n",
    "\n",
    "# print(\"Best params (top-200):\", grid_sel.best_params_)\n",
    "# print(f\"Best CV R² (top-200): {grid_sel.best_score_:.3f}\")\n",
    "\n",
    "# # --- Final evaluation ---\n",
    "# best_rf_sel = grid_sel.best_estimator_\n",
    "# y_pred_train = best_rf_sel.predict(X_train_sel)\n",
    "# y_pred_test = best_rf_sel.predict(X_test_sel)\n",
    "\n",
    "# r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "# r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "# rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "# print(f\"Train R²:  {r2_train:.3f},  RMSE: {rmse_train:.3f}\")\n",
    "# print(f\"Test  R²:  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd80627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insulin                                                    0.146824\n",
      "Biguanide                                                  0.127733\n",
      "Sulfonylurea                                               0.056890\n",
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                 0.046165\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m          0.021422\n",
      "P_WHQ__WHQ150_Age_when_heaviest_weight                     0.021406\n",
      "P_ALB_CR__URDACT_Albumin_creatinine_ratio_mg_g             0.019649\n",
      "P_BIOPRO__LBXSNASI_Sodium_mmol_L                           0.016871\n",
      "P_BIOPRO__LBXSAPSI_Alkaline_Phosphatase_ALP_IU_L           0.014623\n",
      "P_BIOPRO__LBXSCLSI_Chloride_mmol_L                         0.013443\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                      0.012743\n",
      "P_ALB_CR__URXUMS_Albumin_urine_mg_L                        0.011413\n",
      "P_TST__LBXSHBG_SHBG_nmol_L                                 0.011303\n",
      "P_BIOPRO__LBDSUASI_Uric_acid_umol_L                        0.011004\n",
      "P_BIOPRO__LBDSCRSI_Creatinine_refrigerated_serum_umol_L    0.010871\n",
      "P_BPQ__BPQ020_Ever_told_you_had_high_blood_pressure_2.0    0.010573\n",
      "P_BIOPRO__LBDSTRSI_Triglycerides_refrig_serum_mmol_L       0.009948\n",
      "P_CBC__LBXMCHSI_Mean_cell_hemoglobin_pg                    0.009308\n",
      "P_CBC__LBXRDW_Red_cell_distribution_width                  0.009055\n",
      "P_BMX__BMXWAIST_Waist_Circumference_cm                     0.008510\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # assuming your best model is named best_rf_sel or rf_sel\n",
    "# importances = pd.Series(best_rf_sel.feature_importances_, index=X_train_sel.columns)\n",
    "\n",
    "# top20 = importances.sort_values(ascending=False).head(20)\n",
    "# print(top20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fed6d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 3 medication-related features: ['Biguanide', 'Insulin', 'Sulfonylurea']\n",
      "Train R² (no meds):  0.869,  RMSE: 0.377\n",
      "Test  R² (no meds):  0.413,  RMSE: 0.882\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # encode\n",
    "# X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "# X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "# X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# # 1. remove medication-related columns (adjust if names differ)\n",
    "# med_cols = [col for col in X_encoded.columns if any(med in col.lower() for med in [\n",
    "#     'insulin', 'biguanide', 'sulfonylurea'\n",
    "# ])]\n",
    "\n",
    "# print(f\"Removing {len(med_cols)} medication-related features: {med_cols}\")\n",
    "\n",
    "# X_train_nomeds = X_encoded.drop(columns=med_cols, errors='ignore')\n",
    "# X_test_nomeds = X_test_encoded.drop(columns=med_cols, errors='ignore')\n",
    "\n",
    "# # 2. re-fit random forest with same parameters\n",
    "# rf_nomeds = RandomForestRegressor(\n",
    "#     n_estimators=200,\n",
    "#     max_depth=None,\n",
    "#     min_samples_leaf=2,\n",
    "#     min_samples_split=2,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# rf_nomeds.fit(X_train_nomeds, y_train.iloc[:, 0])\n",
    "\n",
    "# # 3. evaluate\n",
    "# y_pred_train = rf_nomeds.predict(X_train_nomeds)\n",
    "# y_pred_test = rf_nomeds.predict(X_test_nomeds)\n",
    "\n",
    "# r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "# r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "# rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "# print(f\"Train R² (no meds):  {r2_train:.3f},  RMSE: {rmse_train:.3f}\")\n",
    "# print(f\"Test  R² (no meds):  {r2_test:.3f},  RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157f493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                 0.135181\n",
      "P_ALB_CR__URDACT_Albumin_creatinine_ratio_mg_g             0.054003\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m          0.045824\n",
      "P_BIOPRO__LBXSNASI_Sodium_mmol_L                           0.040157\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                      0.037009\n",
      "P_BIOPRO__LBXSCLSI_Chloride_mmol_L                         0.023961\n",
      "P_BIOPRO__LBXSAPSI_Alkaline_Phosphatase_ALP_IU_L           0.019127\n",
      "P_TST__LBXSHBG_SHBG_nmol_L                                 0.018281\n",
      "DPP-4 inhibitor                                            0.016312\n",
      "P_BIOPRO__LBDSUASI_Uric_acid_umol_L                        0.016098\n",
      "P_BIOPRO__LBDSCRSI_Creatinine_refrigerated_serum_umol_L    0.015210\n",
      "P_BIOPRO__LBDSTRSI_Triglycerides_refrig_serum_mmol_L       0.014963\n",
      "P_ALB_CR__URXUMS_Albumin_urine_mg_L                        0.014203\n",
      "P_CBC__LBXRDW_Red_cell_distribution_width                  0.012538\n",
      "P_CBC__LBXMCHSI_Mean_cell_hemoglobin_pg                    0.011740\n",
      "Pulse_median                                               0.010756\n",
      "P_WHQ__WHQ150_Age_when_heaviest_weight                     0.010308\n",
      "P_CBC__LBXMC_Mean_Cell_Hgb_Conc_g_dL                       0.009789\n",
      "P_CBC__LBXMPSI_Mean_platelet_volume_fL                     0.009694\n",
      "P_WHQ__WHD050_Self_reported_weight_1_yr_ago_pounds         0.008871\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # assuming your best model is named best_rf_sel or rf_sel\n",
    "# importances = pd.Series(rf_nomeds.feature_importances_, index=X_train_nomeds.columns)\n",
    "\n",
    "# top20 = importances.sort_values(ascending=False).head(20)\n",
    "# print(top20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dc532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.255264945835961, tolerance: 0.6919165839216944\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8731201201742351, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.834399000700614, tolerance: 0.6795716652222762\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.154608527275286, tolerance: 0.6919165839216944\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.586030223753141, tolerance: 0.6795716652222762\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6.054266297646791, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.598445375712345, tolerance: 0.6998679897287743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.069213823775044, tolerance: 0.6425395641149099\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.150938684011862, tolerance: 0.6795716652222762\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.9954669175645, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.6108422954298476, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.32853589544675, tolerance: 0.6919165839216944\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204.15417092597556, tolerance: 0.6919165839216944\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.70627942587953, tolerance: 0.6795716652222762\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.59103376445955, tolerance: 0.6425395641149099\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 143.9612469030883, tolerance: 0.6998679897287743\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.487814402523554, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:683: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.2434996105707796, tolerance: 0.6793605145241515\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.006952\n",
      "Best l1_ratio: 0.90\n",
      "Train R²:  0.739, RMSE: 0.533\n",
      "Test  R²:  0.745, RMSE: 0.581\n",
      "Non-zero features: 267\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                     1.626816\n",
      "P_BIOPRO__LBXSNASI_Sodium_mmol_L                         -1.402458\n",
      "P_BIOPRO__LBDSBUSI_Blood_Urea_Nitrogen_mmol_L            -0.617181\n",
      "Insulin                                                   0.203699\n",
      "Biguanide                                                 0.129168\n",
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                0.123189\n",
      "Sulfonylurea                                              0.078501\n",
      "P_CBC__LBXMCHSI_Mean_cell_hemoglobin_pg                  -0.066415\n",
      "P_DEMO__RIDRETH3_Race_Hispanic_origin_w_NH_Asian_4.0      0.049867\n",
      "P_TST__LBXSHBG_SHBG_nmol_L                               -0.041929\n",
      "P_BIOPRO__LBDSTBSI_Total_Bilirubin_umol_L                -0.037899\n",
      "P_CBC__LBXLYPCT_Lymphocyte_percent                        0.037379\n",
      "P_BIOPRO__LBXSCLSI_Chloride_mmol_L                       -0.037264\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m         0.032389\n",
      "P_FASTQX__PHDSESN_Session_in_which_SP_was_examined_1.0    0.027164\n",
      "P_BMX__BMXLEG_Upper_Leg_Length_cm                        -0.026939\n",
      "P_BIOPRO__LBXSAL_Albumin_refrigerated_serum_g_dL         -0.026438\n",
      "P_CBC__LBXRBCSI_Red_blood_cell_count_million_cells_uL     0.024260\n",
      "P_CBC__LBDMONO_Monocyte_number_1000_cells_uL              0.023342\n",
      "P_BIOPRO__LBDSGBSI_Globulin_g_L                           0.022624\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import ElasticNetCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # encode\n",
    "# X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "# X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "# X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# # pipeline\n",
    "# enet = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     ElasticNetCV(\n",
    "#         l1_ratio=[0.1, 0.3, 0.5, 0.7, 0.9],  # test different L1/L2 mixes\n",
    "#         alphas=np.logspace(-4, 1, 20),\n",
    "#         cv=5,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#         max_iter=5000\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# enet.fit(X_encoded, y_train.iloc[:, 0])\n",
    "\n",
    "# y_pred_train = enet.predict(X_encoded)\n",
    "# y_pred_test = enet.predict(X_test_encoded)\n",
    "\n",
    "# r2_train = r2_score(y_train.iloc[:, 0], y_pred_train)\n",
    "# r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_train.iloc[:, 0], y_pred_train))\n",
    "# rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "# model = enet.named_steps['elasticnetcv']\n",
    "# print(f\"Best alpha: {model.alpha_:.6f}\")\n",
    "# print(f\"Best l1_ratio: {model.l1_ratio_:.2f}\")\n",
    "# print(f\"Train R²:  {r2_train:.3f}, RMSE: {rmse_train:.3f}\")\n",
    "# print(f\"Test  R²:  {r2_test:.3f}, RMSE: {rmse_test:.3f}\")\n",
    "\n",
    "# # coefficients\n",
    "# coef = pd.Series(model.coef_, index=X_encoded.columns)\n",
    "# nonzero = coef[coef != 0].sort_values(key=abs, ascending=False)\n",
    "# print(f\"Non-zero features: {len(nonzero)}\")\n",
    "# print(nonzero.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc591f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    36\n",
      "bool       25\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  LBXGH   No. Observations:                 7789\n",
      "Model:                            GLM   Df Residuals:                     7728\n",
      "Model Family:                   Gamma   Df Model:                           60\n",
      "Link Function:                    log   Scale:                       0.0065927\n",
      "Method:                          IRLS   Log-Likelihood:                -4831.2\n",
      "Date:                Sun, 09 Nov 2025   Deviance:                       48.556\n",
      "Time:                        22:03:43   Pearson chi2:                     50.9\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.9415\n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================================================\n",
      "                                                                   coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "const                                                            1.2919      0.076     17.107      0.000       1.144       1.440\n",
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                       0.0013   7.44e-05     17.144      0.000       0.001       0.001\n",
      "P_BMX__BMXLEG_Upper_Leg_Length_cm                               -0.0011      0.000     -3.572      0.000      -0.002      -0.000\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m                0.0001   1.77e-05      5.713      0.000    6.64e-05       0.000\n",
      "P_ALB_CR__URXUMS_Albumin_urine_mg_L                           6.864e-06   2.89e-06      2.374      0.018     1.2e-06    1.25e-05\n",
      "P_BIOPRO__LBXSAL_Albumin_refrigerated_serum_g_dL                -0.0082      0.004     -2.324      0.020      -0.015      -0.001\n",
      "P_BIOPRO__LBDSBUSI_Blood_Urea_Nitrogen_mmol_L                   -0.0429      0.001    -49.642      0.000      -0.045      -0.041\n",
      "P_BIOPRO__LBXSCLSI_Chloride_mmol_L                              -0.0015      0.000     -3.037      0.002      -0.002      -0.001\n",
      "P_BIOPRO__LBDSCRSI_Creatinine_refrigerated_serum_umol_L      -7.393e-05   2.65e-05     -2.787      0.005      -0.000   -2.19e-05\n",
      "P_BIOPRO__LBDSGBSI_Globulin_g_L                                  0.0009      0.000      3.584      0.000       0.000       0.001\n",
      "P_BIOPRO__LBXSLDSI_Lactate_Dehydrogenase_LDH_IU_L                0.0001   2.84e-05      4.006      0.000    5.81e-05       0.000\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                            0.0423      0.001     70.715      0.000       0.041       0.043\n",
      "P_BIOPRO__LBDSPHSI_Phosphorus_mmol_L                             0.0238      0.006      4.288      0.000       0.013       0.035\n",
      "P_BIOPRO__LBXSNASI_Sodium_mmol_L                                -0.0783      0.001    -66.170      0.000      -0.081      -0.076\n",
      "P_BIOPRO__LBDSTBSI_Total_Bilirubin_umol_L                       -0.0017      0.000     -7.897      0.000      -0.002      -0.001\n",
      "P_CBC__LBXLYPCT_Lymphocyte_percent                               0.0008      0.000      7.046      0.000       0.001       0.001\n",
      "P_CBC__LBDMONO_Monocyte_number_1000_cells_uL                     0.0318      0.005      6.227      0.000       0.022       0.042\n",
      "P_CBC__LBXRBCSI_Red_blood_cell_count_million_cells_uL            0.0113      0.003      4.436      0.000       0.006       0.016\n",
      "P_CBC__LBXMC_Mean_Cell_Hgb_Conc_g_dL                            -0.0030      0.002     -2.004      0.045      -0.006   -6.59e-05\n",
      "P_CBC__LBXMCHSI_Mean_cell_hemoglobin_pg                         -0.0046      0.001     -7.262      0.000      -0.006      -0.003\n",
      "P_CBC__LBXNRBC_Nucleated_red_blood_cells_100_WBC                -0.0528      0.013     -4.050      0.000      -0.078      -0.027\n",
      "P_IHGEM__LBDIHGSI_Mercury_inorganic_nmol_L                       0.0005      0.000      1.664      0.096   -8.44e-05       0.001\n",
      "P_PBCD__LBDBCDSI_Blood_cadmium_nmol_L                            0.0008      0.000      3.593      0.000       0.000       0.001\n",
      "P_TCHOL__LBDTCSI_Total_Cholesterol_mmol_L                        0.0022      0.001      2.198      0.028       0.000       0.004\n",
      "P_TST__LBD17HSI_17_hydroxyprogesterone_nmol_L                   -0.0010      0.001     -1.732      0.083      -0.002       0.000\n",
      "P_TST__LBXSHBG_SHBG_nmol_L                                      -0.0002    2.6e-05     -7.806      0.000      -0.000      -0.000\n",
      "P_MCQ__MCQ160C                                                  -0.0069      0.002     -2.962      0.003      -0.011      -0.002\n",
      "P_MCQ__MCQ366B                                                  -0.0051      0.002     -2.540      0.011      -0.009      -0.001\n",
      "P_PAQ__PAD680_Minutes_sedentary_activity                     -1.767e-05   5.03e-06     -3.511      0.000   -2.75e-05   -7.81e-06\n",
      "Biguanide                                                        0.0733      0.004     18.835      0.000       0.066       0.081\n",
      "DPP-4 inhibitor                                                  0.0180      0.009      2.105      0.035       0.001       0.035\n",
      "Insulin                                                          0.1592      0.005     28.971      0.000       0.148       0.170\n",
      "SGLT2 inhibitor                                                  0.0286      0.012      2.351      0.019       0.005       0.052\n",
      "Sulfonylurea                                                     0.0621      0.006     10.931      0.000       0.051       0.073\n",
      "Thiazolidinedione (TZD)                                          0.0467      0.013      3.690      0.000       0.022       0.072\n",
      "BP_sys_median                                                    0.0001   6.19e-05      1.769      0.077   -1.18e-05       0.000\n",
      "P_DEMO__RIDRETH3_Race_Hispanic_origin_w_NH_Asian_3.0            -0.0109      0.002     -4.662      0.000      -0.015      -0.006\n",
      "P_DEMO__RIDRETH3_Race_Hispanic_origin_w_NH_Asian_4.0             0.0170      0.003      6.229      0.000       0.012       0.022\n",
      "P_BMX__BMDSTATS_Body_Measures_Component_Status_Code_4.0         -0.0281      0.009     -3.300      0.001      -0.045      -0.011\n",
      "P_FASTQX__PHDSESN_Session_in_which_SP_was_examined_1.0           0.0095      0.002      4.891      0.000       0.006       0.013\n",
      "P_ALQ__ALQ121_Past_12_mo_how_often_drink_alcoholic_bev_1.0      -0.0277      0.006     -4.393      0.000      -0.040      -0.015\n",
      "P_ALQ__ALQ121_Past_12_mo_how_often_drink_alcoholic_bev_2.0      -0.0259      0.006     -4.460      0.000      -0.037      -0.015\n",
      "P_ALQ__ALQ121_Past_12_mo_how_often_drink_alcoholic_bev_4.0      -0.0113      0.003     -3.384      0.001      -0.018      -0.005\n",
      "P_BPQ__BPQ080_Doctor_told_you_high_cholesterol_level_2.0        -0.0078      0.002     -3.315      0.001      -0.012      -0.003\n",
      "P_DBQ__DBD900_of_meals_from_fast_food_or_pizza_place_13.0        0.1118      0.041      2.739      0.006       0.032       0.192\n",
      "P_DPQ__DPQ090_Thoughts_you_would_be_better_off_dead_3.0          0.0574      0.017      3.460      0.001       0.025       0.090\n",
      "P_HUQ__HUQ010_General_health_condition_4.0                       0.0043      0.003      1.725      0.084      -0.001       0.009\n",
      "P_MCQ__MCQ053_Taking_treatment_for_anemia_past_3_mos_2.0         0.0221      0.005      4.879      0.000       0.013       0.031\n",
      "P_OHQ__OHQ030_When_did_you_last_visit_a_dentist_6.0             -0.0103      0.003     -3.617      0.000      -0.016      -0.005\n",
      "P_OHQ__OHQ033_Main_reason_for_last_dental_visit_3.0              0.0033      0.002      1.507      0.132      -0.001       0.008\n",
      "P_SLQ__SLQ300_Usual_sleep_time_on_weekdays_or_workdays_14:00    -0.0893      0.030     -3.008      0.003      -0.147      -0.031\n",
      "P_SLQ__SLQ300_Usual_sleep_time_on_weekdays_or_workdays_23:15    -0.1390      0.037     -3.807      0.000      -0.210      -0.067\n",
      "P_SLQ__SLQ310_Usual_wake_time_on_weekdays_or_workdays_00:30     -0.3141      0.082     -3.845      0.000      -0.474      -0.154\n",
      "P_SLQ__SLQ310_Usual_wake_time_on_weekdays_or_workdays_03:10      0.2583      0.082      3.162      0.002       0.098       0.418\n",
      "P_SLQ__SLQ310_Usual_wake_time_on_weekdays_or_workdays_06:10      0.0654      0.022      2.943      0.003       0.022       0.109\n",
      "P_SLQ__SLQ310_Usual_wake_time_on_weekdays_or_workdays_08:15      0.2726      0.082      3.337      0.001       0.112       0.433\n",
      "P_SLQ__SLQ310_Usual_wake_time_on_weekdays_or_workdays_14:50     -0.2860      0.081     -3.513      0.000      -0.445      -0.126\n",
      "P_SLQ__SLQ330_Usual_wake_time_on_weekends_12:30                 -0.1172      0.037     -3.205      0.001      -0.189      -0.046\n",
      "P_SLQ__SLD013_Sleep_hours_weekends_4.0                           0.0304      0.009      3.239      0.001       0.012       0.049\n",
      "P_SLQ__SLQ030_How_often_do_you_snore_3.0                         0.0065      0.002      2.851      0.004       0.002       0.011\n",
      "P_SMQSHS__SMQ856_Last_7_d_worked_at_job_not_at_home_2.0         -0.0089      0.002     -4.517      0.000      -0.013      -0.005\n",
      "================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# import statsmodels.api as sm\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # take important features\n",
    "# enet_model = enet.named_steps['elasticnetcv']\n",
    "# coef = pd.Series(enet_model.coef_, index=X_encoded.columns)\n",
    "# selected_features = coef[coef.abs() > 0.01].index.tolist()\n",
    "\n",
    "\n",
    "# # subset first\n",
    "# X_sub = X_encoded[selected_features].copy()\n",
    "\n",
    "# # force all columns numeric\n",
    "# X_sub = X_sub.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# # add constant\n",
    "# X_glm = sm.add_constant(X_sub)\n",
    "\n",
    "# # make sure y is numeric\n",
    "# y_glm = pd.to_numeric(y_train.iloc[:, 0], errors='coerce')\n",
    "\n",
    "# # drop any rows with NaNs introduced by coercion\n",
    "# mask = X_glm.notnull().all(axis=1) & y_glm.notnull()\n",
    "# X_glm = X_glm.loc[mask]\n",
    "# y_glm = y_glm.loc[mask]\n",
    "\n",
    "# # confirm types\n",
    "# print(X_glm.dtypes.value_counts())\n",
    "\n",
    "# # fit Gamma GLM\n",
    "# glm_model = sm.GLM(\n",
    "#     y_glm.astype(float),\n",
    "#     X_glm.astype(float),\n",
    "#     family=sm.families.Gamma(link=sm.families.links.log())\n",
    "# ).fit()\n",
    "\n",
    "# print(glm_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5b07df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R²:  0.718, RMSE: 0.554\n",
      "Test  R²:  0.729, RMSE: 0.599\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "# import numpy as np\n",
    "\n",
    "# # prepare test set the same way\n",
    "# X_test_sub = X_test_encoded[selected_features].copy()\n",
    "# X_test_sub = X_test_sub.apply(pd.to_numeric, errors='coerce')\n",
    "# X_test_glm = sm.add_constant(X_test_sub, has_constant='add')\n",
    "\n",
    "# # align columns\n",
    "# X_test_glm = X_test_glm.reindex(columns=X_glm.columns, fill_value=0)\n",
    "\n",
    "# # predictions\n",
    "# # ensure numeric numpy arrays for prediction\n",
    "# y_pred_train = glm_model.predict(np.asarray(X_glm, dtype=float))\n",
    "# y_pred_test = glm_model.predict(np.asarray(X_test_glm, dtype=float))\n",
    "\n",
    "\n",
    "# # metrics\n",
    "# r2_train = r2_score(y_glm, y_pred_train)\n",
    "# r2_test = r2_score(y_test.iloc[:, 0], y_pred_test)\n",
    "# rmse_train = np.sqrt(mean_squared_error(y_glm, y_pred_train))\n",
    "# rmse_test = np.sqrt(mean_squared_error(y_test.iloc[:, 0], y_pred_test))\n",
    "\n",
    "# print(f\"Train R²:  {r2_train:.3f}, RMSE: {rmse_train:.3f}\")\n",
    "# print(f\"Test  R²:  {r2_test:.3f}, RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba72fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM Gaussian — Train R²: 0.679, RMSE: 0.591 | Test R²: 0.704, RMSE: 0.626\n",
      "GLM Gamma —    Train R²: 0.659, RMSE: 0.609 | Test R²: 0.660, RMSE: 0.672\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# # 1. Take top 50 (or 100) variables\n",
    "# top_vars = importances.sort_values(ascending=False).head(100).index\n",
    "# X_train_top = X_train_nomeds[top_vars]\n",
    "# X_test_top = X_test_nomeds[top_vars]\n",
    "\n",
    "# # 2. Convert to numeric and add constant\n",
    "# X_train_const = sm.add_constant(X_train_top)\n",
    "# X_test_const = sm.add_constant(X_test_top)\n",
    "\n",
    "# # 3. Force all to float numpy arrays\n",
    "# X_train_arr = np.asarray(X_train_const, dtype=float)\n",
    "# X_test_arr = np.asarray(X_test_const, dtype=float)\n",
    "# y_train_vec = np.asarray(y_train.iloc[:, 0], dtype=float)\n",
    "# y_test_vec = np.asarray(y_test.iloc[:, 0], dtype=float)\n",
    "\n",
    "# # 4. Fit models\n",
    "# glm_gaussian = sm.GLM(y_train_vec, X_train_arr, family=sm.families.Gaussian())\n",
    "# res_gaussian = glm_gaussian.fit()\n",
    "\n",
    "# glm_gamma = sm.GLM(y_train_vec, X_train_arr, family=sm.families.Gamma(sm.families.links.log()))\n",
    "# res_gamma = glm_gamma.fit()\n",
    "\n",
    "# # 5. Predictions\n",
    "# y_pred_train_gaussian = res_gaussian.predict(X_train_arr)\n",
    "# y_pred_test_gaussian = res_gaussian.predict(X_test_arr)\n",
    "\n",
    "# y_pred_train_gamma = res_gamma.predict(X_train_arr)\n",
    "# y_pred_test_gamma = res_gamma.predict(X_test_arr)\n",
    "\n",
    "# # 6. Metrics\n",
    "# def metrics(y_true, y_pred):\n",
    "#     return r2_score(y_true, y_pred), np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# r2_train_g, rmse_train_g = metrics(y_train_vec, y_pred_train_gaussian)\n",
    "# r2_test_g, rmse_test_g = metrics(y_test_vec, y_pred_test_gaussian)\n",
    "\n",
    "# r2_train_gamma, rmse_train_gamma = metrics(y_train_vec, y_pred_train_gamma)\n",
    "# r2_test_gamma, rmse_test_gamma = metrics(y_test_vec, y_pred_test_gamma)\n",
    "\n",
    "# # 7. Print\n",
    "# print(f\"GLM Gaussian — Train R²: {r2_train_g:.3f}, RMSE: {rmse_train_g:.3f} | \"\n",
    "#       f\"Test R²: {r2_test_g:.3f}, RMSE: {rmse_test_g:.3f}\")\n",
    "\n",
    "# print(f\"GLM Gamma —    Train R²: {r2_train_gamma:.3f}, RMSE: {rmse_train_gamma:.3f} | \"\n",
    "#       f\"Test R²: {r2_test_gamma:.3f}, RMSE: {rmse_test_gamma:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "182177c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.to_csv(\"LOG/X_encoded_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced571b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The log link alias is deprecated. Use Log instead. The log link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLM Gaussian (log link) — Train R²: 0.671, RMSE: 0.598 | Test R²: 0.675, RMSE: 0.656\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import statsmodels.api as sm\n",
    "# from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# # 1. Take top variables (e.g., top 100)\n",
    "# top_vars = importances.sort_values(ascending=False).head(100).index\n",
    "# X_train_top = X_train_nomeds[top_vars]\n",
    "# X_test_top = X_test_nomeds[top_vars]\n",
    "\n",
    "# # 2. Convert to numeric and add constant\n",
    "# X_train_const = sm.add_constant(X_train_top)\n",
    "# X_test_const = sm.add_constant(X_test_top)\n",
    "\n",
    "# # 3. Force all to float numpy arrays\n",
    "# X_train_arr = np.asarray(X_train_const, dtype=float)\n",
    "# X_test_arr = np.asarray(X_test_const, dtype=float)\n",
    "# y_train_vec = np.asarray(y_train.iloc[:, 0], dtype=float)\n",
    "# y_test_vec = np.asarray(y_test.iloc[:, 0], dtype=float)\n",
    "\n",
    "# # 4. Fit Gaussian with log link\n",
    "# glm_gaussian_log = sm.GLM(\n",
    "#     y_train_vec, \n",
    "#     X_train_arr, \n",
    "#     family=sm.families.Gaussian(sm.families.links.log())\n",
    "# )\n",
    "# res_gaussian_log = glm_gaussian_log.fit()\n",
    "\n",
    "# # 5. Predict\n",
    "# y_pred_train = res_gaussian_log.predict(X_train_arr)\n",
    "# y_pred_test = res_gaussian_log.predict(X_test_arr)\n",
    "\n",
    "# # 6. Metrics\n",
    "# def metrics(y_true, y_pred):\n",
    "#     return r2_score(y_true, y_pred), np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# r2_train, rmse_train = metrics(y_train_vec, y_pred_train)\n",
    "# r2_test, rmse_test = metrics(y_test_vec, y_pred_test)\n",
    "\n",
    "# # 7. Print\n",
    "# print(f\"GLM Gaussian (log link) — Train R²: {r2_train:.3f}, RMSE: {rmse_train:.3f} | \"\n",
    "#       f\"Test R²: {r2_test:.3f}, RMSE: {rmse_test:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4995e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_DEMO__RIDAGEYR_Age_in_years_at                       0.135181\n",
      "P_ALB_CR__URDACT_Albumin_creatinine_ratio_mg           0.054003\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB        0.045824\n",
      "P_BIOPRO__LBXSNASI_Sodium_mmol                         0.040157\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol                     0.037009\n",
      "                                                         ...   \n",
      "P_COT__LBXHCOT_Hydroxycotinine_Serum_ng                0.002412\n",
      "P_FETIB__LBDPCT_Transferrin                            0.002403\n",
      "P_BIOPRO__LBXSC3SI_Bicarbonate_mmol                    0.002379\n",
      "P_DPQ__DPQ090_Thoughts_you_would_be_better_off_dead    0.002368\n",
      "P_COT__LBXCOT_Cotinine_Serum_ng                        0.002365\n",
      "Length: 100, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import re\n",
    "\n",
    "# # Get feature importances from your fitted RF\n",
    "# importances = pd.Series(rf_nomeds.feature_importances_, index=X_train_nomeds.columns)\n",
    "\n",
    "# # Group by base variable name — everything before the last underscore or last category part\n",
    "# def base_name(col):\n",
    "#     # adjust the pattern if your naming scheme differs\n",
    "#     return re.split(r'_[^_]+$', col)[0]\n",
    "\n",
    "# # Group and sum\n",
    "# grouped_importances = importances.groupby(base_name).sum().sort_values(ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
