{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9ae294d",
   "metadata": {},
   "source": [
    "# Collinearity and Leakage Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f98e8ff",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "__Collinearity (Moved to later part)__  \n",
    "step 2 - Run the VIF -> drop the highest -> Repeat (Threshold VIF < 5)  \n",
    "Note:\n",
    "* unlike p-value which the choice of drop is arbitrary, VIF check against the remaining variables which give clear values\n",
    "* modern ML can handle multicollinearity but GLM struggle  \n",
    "* the VIF will be run after variable selection only for GLM, but not for trees\n",
    "\n",
    "__Leakage Test__  \n",
    "step 3 - Check p-value against the predictor for regression data. Check if p-value is suspiciously high.  \n",
    "step 4 - Run random forest against the data (can use default param). Check top 10 feature importance and check manually for a potential leakage.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fdce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# stats\n",
    "from scipy.stats import ks_2samp, chi2_contingency, pearsonr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99acfa5",
   "metadata": {},
   "source": [
    "__Split Distribution__  \n",
    "Step 1 - Perform distribution test, Kolgomorov-Smirnov for continuous, Chi-square for categorical  \n",
    "\n",
    "> KS test: 2 variables (1.60%) have p < 0.05\n",
    "> Chi-square test: 4 variables (3.05%) have p < 0.05\n",
    ">\n",
    "> Conclusion: The train-test split preserved the distribution well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4127549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"PROCESSED/DATA/merged_and_dropped.cat_cols.json\") as f:\n",
    "    cat_cols = json.load(f)\n",
    "\n",
    "X_train = pd.read_parquet(\"INPUTS/TRAIN/X_train.parquet\")\n",
    "X_test = pd.read_parquet(\"INPUTS/TEST/X_test.parquet\")\n",
    "y_train = pd.read_parquet(\"INPUTS/TRAIN/y_train.parquet\")\n",
    "y_test = pd.read_parquet(\"INPUTS/TEST/y_test.parquet\")\n",
    "\n",
    "X_train[cat_cols] = X_train[cat_cols].astype(\"category\")\n",
    "X_test[cat_cols] = X_test[cat_cols].astype(\"category\")\n",
    "\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f657a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_DEMO__RIDAGEYR_Age_in_years_at_screening                  0.107723\n",
      "P_LUX__LUXCAPM_Median_CAP_decibels_per_meter_dB_m           0.056829\n",
      "P_ALB_CR__URDACT_Albumin_creatinine_ratio_mg_g              0.048834\n",
      "P_MCQ__MCQ366D                                              0.021322\n",
      "P_MCQ__MCQ300C                                              0.020041\n",
      "P_TCHOL__LBDTCSI_Total_Cholesterol_mmol_L                   0.019221\n",
      "P_ALB_CR__URXUMS_Albumin_urine_mg_L                         0.018319\n",
      "P_BPQ__BPQ020_Ever_told_you_had_high_blood_pressure_2.0     0.016682\n",
      "P_BIOPRO__LBDSCHSI_Cholesterol_refrigerated_serum_mmol_L    0.016425\n",
      "P_BIOPRO__LBXSOSSI_Osmolality_mmol_Kg                       0.014955\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode categorical variables\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf.fit(X_encoded, y_train.iloc[:, 0])\n",
    "importances = pd.Series(rf.feature_importances_, index=X_encoded.columns)\n",
    "top10 = importances.sort_values(ascending=False).head(10)\n",
    "print(top10)\n",
    "# top10.to_csv(\"LOG/rf_leakage_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5759f",
   "metadata": {},
   "source": [
    "#### Initial test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d2cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best CV score: 0.6054338112411181\n",
      "CV AUC at best-AUC params: 0.8777209115251665\n",
      "CV F1 at best-AUC params: 0.6054338112411181\n",
      "CV Accuracy at best-AUC params: 0.8506862843401745\n",
      "Train accuracy: 0.936,  F1: 0.868, AUC: 0.995\n",
      "Test  accuracy: 0.872,  F1: 0.649, AUC: 0.896\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.99      0.93      1642\n",
      "         1.0       0.81      0.24      0.37       306\n",
      "\n",
      "    accuracy                           0.87      1948\n",
      "   macro avg       0.84      0.61      0.65      1948\n",
      "weighted avg       0.86      0.87      0.84      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, make_scorer, roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# ensure target is categorical\n",
    "y_train_cat = y_train.iloc[:, 0].astype(\"category\")\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(\"category\")\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# model\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "scorers = {\n",
    "    'auc': 'roc_auc_ovr',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_encoded, y_train_cat)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "# evaluate on train/test\n",
    "best_rf = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_rf.predict(X_encoded)\n",
    "y_pred_test  = best_rf.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_cat, best_rf.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_cat, best_rf.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c41d420f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.856,  F1: 0.691\n",
      "Test  accuracy: 0.868,  F1: 0.698\n",
      "Train AUC: 0.860\n",
      "Test  AUC: 0.877\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.96      0.92      1642\n",
      "         1.0       0.64      0.38      0.47       306\n",
      "\n",
      "    accuracy                           0.87      1948\n",
      "   macro avg       0.76      0.67      0.70      1948\n",
      "weighted avg       0.85      0.87      0.85      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# target as categorical\n",
    "y_train_cat = y_train.iloc[:, 0].astype(\"category\")\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(\"category\")\n",
    "\n",
    "# unregularized logistic regression (GLM)\n",
    "model = LogisticRegression(\n",
    "    penalty=None,        # FIX: unregularized\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=500,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "model.fit(X_encoded, y_train_cat)\n",
    "\n",
    "# predictions\n",
    "y_pred_train = model.predict(X_encoded)\n",
    "y_pred_test  = model.predict(X_test_encoded)\n",
    "\n",
    "# metrics\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average=\"macro\")\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average=\"macro\")\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}\")\n",
    "print(f\"Train AUC: {roc_auc_score(y_train_cat, model.predict_proba(X_encoded)[:, 1]):.3f}\")\n",
    "print(f\"Test  AUC: {roc_auc_score(y_test_cat, model.predict_proba(X_test_encoded)[:, 1]):.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e85bfb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best parameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best CV score: 0.7775390646263148\n",
      "CV AUC at best-AUC params: 0.9157619049539963\n",
      "CV F1 at best-AUC params: 0.7775390646263148\n",
      "CV Accuracy at best-AUC params: 0.8886887283913188\n",
      "Train accuracy: 0.944,  F1: 0.891, AUC: 0.980\n",
      "Test  accuracy: 0.914,  F1: 0.819, AUC: 0.934\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1642\n",
      "           1       0.80      0.60      0.69       306\n",
      "\n",
      "    accuracy                           0.91      1948\n",
      "   macro avg       0.86      0.79      0.82      1948\n",
      "weighted avg       0.91      0.91      0.91      1948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, make_scorer\n",
    "import pandas as pd\n",
    "\n",
    "# encode\n",
    "X_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_encoded.columns, fill_value=0)\n",
    "\n",
    "# target\n",
    "y_train_cat = y_train.iloc[:, 0].astype(int)\n",
    "y_test_cat  = y_test.iloc[:, 0].astype(int)\n",
    "\n",
    "# parameter grid (XGB version)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# model\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# scorers\n",
    "scorers = {\n",
    "    'auc': 'roc_auc',\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1': make_scorer(f1_score, average='macro')\n",
    "}\n",
    "\n",
    "# grid search\n",
    "grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scorers,\n",
    "    refit='f1',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit\n",
    "grid.fit(X_encoded, y_train_cat)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best CV score:\", grid.best_score_)\n",
    "print(\"CV AUC at best-AUC params:\", grid.cv_results_['mean_test_auc'][grid.best_index_])\n",
    "print(\"CV F1 at best-AUC params:\", grid.cv_results_['mean_test_f1'][grid.best_index_])\n",
    "print(\"CV Accuracy at best-AUC params:\", grid.cv_results_['mean_test_accuracy'][grid.best_index_])\n",
    "\n",
    "# evaluate\n",
    "best_xgb = grid.best_estimator_\n",
    "\n",
    "y_pred_train = best_xgb.predict(X_encoded)\n",
    "y_pred_test  = best_xgb.predict(X_test_encoded)\n",
    "\n",
    "acc_train = accuracy_score(y_train_cat, y_pred_train)\n",
    "acc_test  = accuracy_score(y_test_cat, y_pred_test)\n",
    "\n",
    "f1_train = f1_score(y_train_cat, y_pred_train, average='macro')\n",
    "f1_test  = f1_score(y_test_cat, y_pred_test, average='macro')\n",
    "\n",
    "auc_train = roc_auc_score(y_train_cat, best_xgb.predict_proba(X_encoded)[:, 1])\n",
    "auc_test  = roc_auc_score(y_test_cat, best_xgb.predict_proba(X_test_encoded)[:, 1])\n",
    "\n",
    "print(f\"Train accuracy: {acc_train:.3f},  F1: {f1_train:.3f}, AUC: {auc_train:.3f}\")\n",
    "print(f\"Test  accuracy: {acc_test:.3f},  F1: {f1_test:.3f}, AUC: {auc_test:.3f}\")\n",
    "\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test_cat, y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
